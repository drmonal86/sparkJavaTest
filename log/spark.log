09:02:23.289 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:02:23.461 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:02:23.679 INFO  o.a.c.config.DatabaseDescriptor - DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
09:02:23.695 INFO  o.a.c.config.DatabaseDescriptor - Global memtable on-heap threshold is enabled at 450MB
09:02:23.695 INFO  o.a.c.config.DatabaseDescriptor - Global memtable off-heap threshold is enabled at 450MB
09:02:23.898 WARN  o.a.c.config.DatabaseDescriptor - Please rename encryption_options as server_encryption_options in the yaml
09:02:24.194 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:02:24.210 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:02:24.272 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:02:24.288 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:02:25.676 INFO  o.a.c.config.DatabaseDescriptor - Couldn't detect any schema definitions in local storage.
09:02:25.676 INFO  o.a.c.config.DatabaseDescriptor - To create keyspaces and column families, see 'help create' in cqlsh.
09:02:26.021 INFO  o.a.c.io.sstable.IndexSummaryManager - Initializing index summary manager with a memory pool size of 13 MB and a resize interval of 60 minutes
09:02:26.067 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:02:26.067 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:02:26.161 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:02:26.161 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:02:26.224 INFO  o.a.cassandra.net.MessagingService - Starting Messaging Service on port 7010
09:02:26.239 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:02:26.255 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:02:26.317 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:02:26.333 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:02:26.380 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:02:26.395 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:02:26.941 INFO  o.apache.cassandra.transport.Server - Using Netty Version: [netty-buffer=netty-buffer-4.0.23.Final.208198c, netty-codec=netty-codec-4.0.23.Final.208198c, netty-codec-http=netty-codec-http-4.0.23.Final.208198c, netty-codec-socks=netty-codec-socks-4.0.23.Final.208198c, netty-common=netty-common-4.0.23.Final.208198c, netty-handler=netty-handler-4.0.23.Final.208198c, netty-transport=netty-transport-4.0.23.Final.208198c, netty-transport-rxtx=netty-transport-rxtx-4.0.23.Final.208198c, netty-transport-sctp=netty-transport-sctp-4.0.23.Final.208198c, netty-transport-udt=netty-transport-udt-4.0.23.Final.208198c]
09:02:26.941 INFO  o.apache.cassandra.transport.Server - Starting listening for CQL clients on localhost/127.0.0.1:9142...
09:02:27.144 INFO  o.a.cassandra.thrift.ThriftServer - Binding thrift service to localhost/127.0.0.1:9171
09:02:27.144 INFO  o.a.cassandra.thrift.ThriftServer - Listening for thrift clients...
09:02:39.130 ERROR b.hashmade.spark.util.RoadTripUtil - Keyspace roadtrips already exists
com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.exceptions.AlreadyExistsException.copy(AlreadyExistsException.java:85) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.extractCauseFromExecutionException(DefaultResultSetFuture.java:259) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:175) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:52) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:36) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.cassandraunit.CQLDataLoader.load(CQLDataLoader.java:36) ~[cassandra-unit-2.0.2.2.jar:na]
	at blog.hashmade.spark.util.RoadTripUtil.initCassandraWithRoadTrips(RoadTripUtil.java:46) ~[classes/:na]
	at blog.hashmade.spark.DatastaxSparkTest.main(DatastaxSparkTest.java:30) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_25]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_25]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_25]
	at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_25]
	at org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:297) [exec-maven-plugin-1.2.1.jar:na]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_25]
Caused by: com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.exceptions.AlreadyExistsException.copy(AlreadyExistsException.java:85) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:105) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.onSet(DefaultResultSetFuture.java:110) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.RequestHandler.setFinalResult(RequestHandler.java:246) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.RequestHandler.onSet(RequestHandler.java:418) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Connection$Dispatcher.messageReceived(Connection.java:661) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:318) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) ~[netty-3.9.0.Final.jar:na]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_25]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_25]
	... 1 common frames omitted
Caused by: com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:70) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:38) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:168) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:66) ~[netty-3.9.0.Final.jar:na]
	... 21 common frames omitted
09:02:39.676 INFO  org.apache.spark.SecurityManager - Changing view acls to: mdoctor,
09:02:39.676 INFO  org.apache.spark.SecurityManager - Changing modify acls to: mdoctor,
09:02:39.691 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(mdoctor, ); users with modify permissions: Set(mdoctor, )
09:02:40.128 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
09:02:40.206 INFO  Remoting - Starting remoting
09:02:40.378 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:53783]
09:02:40.378 INFO  Remoting - Remoting now listens on addresses: [akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:53783]
09:02:40.393 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53783.
09:02:40.425 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
09:02:40.440 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
09:02:40.456 INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\mdoctor\AppData\Local\Temp\spark-local-20150105090240-9eb5
09:02:40.503 INFO  org.apache.spark.util.Utils - Successfully started service 'Connection manager for block manager' on port 53786.
09:02:40.503 INFO  o.a.spark.network.ConnectionManager - Bound socket to port 53786 with id = ConnectionManagerId(MDOCTOR.chi.chicorp,53786)
09:02:40.518 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 972.5 MB
09:02:40.518 INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
09:02:40.518 INFO  o.a.s.s.BlockManagerMasterActor - Registering block manager MDOCTOR.chi.chicorp:53786 with 972.5 MB RAM
09:02:40.534 INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
09:02:40.549 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\mdoctor\AppData\Local\Temp\spark-9ed20f69-d052-4f6b-836a-8b9b77c32bcd
09:02:40.565 INFO  org.apache.spark.HttpServer - Starting HTTP Server
09:02:40.627 INFO  org.eclipse.jetty.server.Server - jetty-8.1.14.v20131031
09:02:40.659 INFO  o.e.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:53787
09:02:40.659 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 53787.
09:02:41.111 INFO  org.eclipse.jetty.server.Server - jetty-8.1.14.v20131031
09:02:41.127 INFO  o.e.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
09:02:41.127 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
09:02:41.142 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://MDOCTOR.chi.chicorp:4040
09:02:41.345 INFO  org.apache.spark.util.AkkaUtils - Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:53783/user/HeartbeatReceiver
09:02:41.710 INFO  c.d.s.c.cql.CassandraConnector - Connected to Cassandra cluster: CassClusterDev001
09:02:41.711 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:02:41.711 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:02:41.715 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:02:41.720 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:02:41.725 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:02:41.756 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:02:41.756 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:02:41.760 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:02:41.766 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:02:41.773 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:02:42.177 INFO  c.d.s.c.cql.CassandraConnector - Disconnected from Cassandra cluster: CassClusterDev001
09:02:42.508 INFO  org.apache.spark.SparkContext - Starting job: collect at DatastaxSparkTest.java:80
09:02:42.524 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 1 (groupBy at DatastaxSparkTest.java:66)
09:02:42.527 INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (collect at DatastaxSparkTest.java:80) with 2 output partitions (allowLocal=false)
09:02:42.527 INFO  o.a.spark.scheduler.DAGScheduler - Final stage: Stage 0(collect at DatastaxSparkTest.java:80)
09:02:42.528 INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 1)
09:02:42.532 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(Stage 1)
09:02:42.537 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 1 (MappedRDD[1] at groupBy at DatastaxSparkTest.java:66), which has no missing parents
09:02:42.584 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(6456) called with curMem=0, maxMem=1019782103
09:02:42.585 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 6.3 KB, free 972.5 MB)
09:02:42.621 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 1 (MappedRDD[1] at groupBy at DatastaxSparkTest.java:66)
09:02:42.622 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 2 tasks
09:02:42.646 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 0, localhost, ANY, 25221 bytes)
09:02:42.650 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 0)
09:02:42.680 INFO  org.apache.spark.CacheManager - Partition rdd_0_0 not found, computing it
09:02:42.850 INFO  c.d.s.c.cql.CassandraConnector - Connected to Cassandra cluster: CassClusterDev001
09:02:42.850 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:02:42.855 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:02:42.855 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:02:42.860 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:02:42.865 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:02:42.895 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:02:42.895 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:02:42.906 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:02:42.907 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:02:42.911 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:02:45.318 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=6456, maxMem=1019782103
09:02:45.320 INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_0 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:02:45.322 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_0 in memory on MDOCTOR.chi.chicorp:53786 (size: 16.0 B, free: 972.5 MB)
09:02:45.324 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_0_0
09:02:45.346 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 0). 1385 bytes result sent to driver
09:02:45.361 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 1, localhost, ANY, 25283 bytes)
09:02:45.364 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 0) in 2724 ms on localhost (1/2)
09:02:45.365 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 1)
09:02:45.422 INFO  org.apache.spark.CacheManager - Partition rdd_0_1 not found, computing it
09:02:47.173 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=6472, maxMem=1019782103
09:02:47.174 INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_1 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:02:47.174 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_1 in memory on MDOCTOR.chi.chicorp:53786 (size: 16.0 B, free: 972.5 MB)
09:02:47.175 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_0_1
09:02:47.176 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 1). 1385 bytes result sent to driver
09:02:47.178 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 1) in 1831 ms on localhost (2/2)
09:02:47.179 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
09:02:47.180 INFO  o.a.spark.scheduler.DAGScheduler - Stage 1 (groupBy at DatastaxSparkTest.java:66) finished in 4.547 s
09:02:47.180 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:02:47.181 INFO  o.a.spark.scheduler.DAGScheduler - running: Set()
09:02:47.181 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 0)
09:02:47.181 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:02:47.185 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 0: List()
09:02:47.187 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 0 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72), which is now runnable
09:02:47.194 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2864) called with curMem=6488, maxMem=1019782103
09:02:47.194 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 2.8 KB, free 972.5 MB)
09:02:47.196 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 0 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72)
09:02:47.196 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 2 tasks
09:02:47.197 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 948 bytes)
09:02:47.197 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 2)
09:02:47.199 INFO  org.apache.spark.CacheManager - Partition rdd_4_0 not found, computing it
09:02:47.205 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:02:47.207 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:02:47.208 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 3 ms
09:02:47.218 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=9352, maxMem=1019782103
09:02:47.218 INFO  org.apache.spark.storage.MemoryStore - Block rdd_4_0 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:02:47.218 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_4_0 in memory on MDOCTOR.chi.chicorp:53786 (size: 16.0 B, free: 972.5 MB)
09:02:47.219 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_4_0
09:02:47.220 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 2). 1391 bytes result sent to driver
09:02:47.221 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 948 bytes)
09:02:47.221 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 2) in 24 ms on localhost (1/2)
09:02:47.222 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 3)
09:02:47.226 INFO  org.apache.spark.CacheManager - Partition rdd_4_1 not found, computing it
09:02:47.226 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:02:47.226 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:02:47.226 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:02:47.226 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=9368, maxMem=1019782103
09:02:47.226 INFO  org.apache.spark.storage.MemoryStore - Block rdd_4_1 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:02:47.227 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_4_1 in memory on MDOCTOR.chi.chicorp:53786 (size: 16.0 B, free: 972.5 MB)
09:02:47.227 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_4_1
09:02:47.227 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 3). 1391 bytes result sent to driver
09:02:47.228 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 3) in 8 ms on localhost (2/2)
09:02:47.228 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
09:02:47.228 INFO  o.a.spark.scheduler.DAGScheduler - Stage 0 (collect at DatastaxSparkTest.java:80) finished in 0.032 s
09:02:47.233 INFO  org.apache.spark.SparkContext - Job finished: collect at DatastaxSparkTest.java:80, took 4.723175323 s
09:02:47.235 INFO  b.hashmade.spark.DatastaxSparkTest - Nb RoadTrips by origin
09:02:47.266 INFO  org.apache.spark.SparkContext - Starting job: collect at DatastaxSparkTest.java:103
09:02:47.269 INFO  o.a.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 148 bytes
09:02:47.270 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 4 (mapToPair at DatastaxSparkTest.java:72)
09:02:47.271 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 5 (mapToPair at DatastaxSparkTest.java:86)
09:02:47.271 INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at DatastaxSparkTest.java:103) with 2 output partitions (allowLocal=false)
09:02:47.271 INFO  o.a.spark.scheduler.DAGScheduler - Final stage: Stage 2(collect at DatastaxSparkTest.java:103)
09:02:47.271 INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 5, Stage 4)
09:02:47.272 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(Stage 5, Stage 4)
09:02:47.272 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 4 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72), which has no missing parents
09:02:47.274 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2768) called with curMem=9384, maxMem=1019782103
09:02:47.274 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.7 KB, free 972.5 MB)
09:02:47.274 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 4 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72)
09:02:47.275 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 2 tasks
09:02:47.276 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4, localhost, ANY, 937 bytes)
09:02:47.277 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 5 (MappedRDD[5] at mapToPair at DatastaxSparkTest.java:86), which has no missing parents
09:02:47.278 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(6464) called with curMem=12152, maxMem=1019782103
09:02:47.278 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 6.3 KB, free 972.5 MB)
09:02:47.280 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 5 (MappedRDD[5] at mapToPair at DatastaxSparkTest.java:86)
09:02:47.280 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 2 tasks
09:02:47.295 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
09:02:47.298 INFO  o.apache.spark.storage.BlockManager - Found block rdd_4_0 locally
09:02:47.313 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1874 bytes result sent to driver
09:02:47.313 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 4.0 (TID 5, localhost, ANY, 937 bytes)
09:02:47.314 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 4.0 (TID 5)
09:02:47.315 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 38 ms on localhost (1/2)
09:02:47.316 INFO  o.apache.spark.storage.BlockManager - Found block rdd_4_1 locally
09:02:47.316 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 4.0 (TID 5). 1874 bytes result sent to driver
09:02:47.318 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 6, localhost, ANY, 25221 bytes)
09:02:47.320 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 4.0 (TID 5) in 7 ms on localhost (2/2)
09:02:47.320 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
09:02:47.321 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 6)
09:02:47.330 INFO  o.a.spark.scheduler.DAGScheduler - Stage 4 (mapToPair at DatastaxSparkTest.java:72) finished in 0.054 s
09:02:47.330 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:02:47.330 INFO  o.a.spark.scheduler.DAGScheduler - running: Set(Stage 5)
09:02:47.330 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 2)
09:02:47.330 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:02:47.333 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List(Stage 5)
09:02:47.335 INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_0 locally
09:02:47.336 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 6). 1874 bytes result sent to driver
09:02:47.338 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 7, localhost, ANY, 25283 bytes)
09:02:47.338 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 6) in 21 ms on localhost (1/2)
09:02:47.340 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 7)
09:02:47.346 INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_1 locally
09:02:47.347 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 7). 1874 bytes result sent to driver
09:02:47.348 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 7) in 12 ms on localhost (2/2)
09:02:47.348 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
09:02:47.349 INFO  o.a.spark.scheduler.DAGScheduler - Stage 5 (mapToPair at DatastaxSparkTest.java:86) finished in 0.069 s
09:02:47.349 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:02:47.349 INFO  o.a.spark.scheduler.DAGScheduler - running: Set()
09:02:47.349 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 2)
09:02:47.349 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:02:47.352 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List()
09:02:47.352 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 2 (MappedValuesRDD[10] at mapValues at DatastaxSparkTest.java:98), which is now runnable
09:02:47.353 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3384) called with curMem=18616, maxMem=1019782103
09:02:47.353 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.3 KB, free 972.5 MB)
09:02:47.356 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 2 (MappedValuesRDD[10] at mapValues at DatastaxSparkTest.java:98)
09:02:47.356 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 2 tasks
09:02:47.356 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 8, localhost, PROCESS_LOCAL, 3237 bytes)
09:02:47.360 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 8)
09:02:47.363 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:02:47.363 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:02:47.363 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 1 ms
09:02:47.364 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:02:47.364 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:02:47.364 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:02:47.367 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 8). 822 bytes result sent to driver
09:02:47.369 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 9, localhost, PROCESS_LOCAL, 3237 bytes)
09:02:47.371 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 8) in 14 ms on localhost (1/2)
09:02:47.371 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 9)
09:02:47.373 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:02:47.375 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:02:47.375 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 2 ms
09:02:47.375 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:02:47.376 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:02:47.376 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 1 ms
09:02:47.377 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 9). 822 bytes result sent to driver
09:02:47.378 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 9) in 9 ms on localhost (2/2)
09:02:47.378 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
09:02:47.378 INFO  o.a.spark.scheduler.DAGScheduler - Stage 2 (collect at DatastaxSparkTest.java:103) finished in 0.022 s
09:02:47.378 INFO  org.apache.spark.SparkContext - Job finished: collect at DatastaxSparkTest.java:103, took 0.112245658 s
09:02:47.379 INFO  b.hashmade.spark.DatastaxSparkTest - Average distance by origin
09:02:47.634 INFO  c.d.s.c.cql.CassandraConnector - Disconnected from Cassandra cluster: CassClusterDev001
09:04:09.527 INFO  o.a.cassandra.thrift.ThriftServer - Stop listening to thrift clients
09:04:09.558 INFO  o.apache.cassandra.transport.Server - Stop listening for CQL clients
09:04:09.574 INFO  org.apache.cassandra.gms.Gossiper - Announcing shutdown
09:04:11.586 INFO  o.a.cassandra.net.MessagingService - Waiting for messaging service to quiesce
09:04:11.586 INFO  o.a.cassandra.net.MessagingService - MessagingService has terminated the accept() thread
09:06:08.977 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:06:09.118 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:06:09.399 INFO  o.a.c.config.DatabaseDescriptor - DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
09:06:09.414 INFO  o.a.c.config.DatabaseDescriptor - Global memtable on-heap threshold is enabled at 450MB
09:06:09.430 INFO  o.a.c.config.DatabaseDescriptor - Global memtable off-heap threshold is enabled at 450MB
09:06:09.617 WARN  o.a.c.config.DatabaseDescriptor - Please rename encryption_options as server_encryption_options in the yaml
09:06:09.914 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:06:09.929 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:06:10.007 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:06:10.038 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:06:11.801 INFO  o.a.c.config.DatabaseDescriptor - Couldn't detect any schema definitions in local storage.
09:06:11.817 INFO  o.a.c.config.DatabaseDescriptor - To create keyspaces and column families, see 'help create' in cqlsh.
09:06:12.161 INFO  o.a.c.io.sstable.IndexSummaryManager - Initializing index summary manager with a memory pool size of 13 MB and a resize interval of 60 minutes
09:06:12.208 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:06:12.224 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:06:12.333 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:06:12.348 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:06:12.458 INFO  o.a.cassandra.net.MessagingService - Starting Messaging Service on port 7010
09:06:12.473 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:06:12.489 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:06:12.582 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:06:12.582 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:06:12.660 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:06:12.676 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:06:13.316 INFO  o.apache.cassandra.transport.Server - Using Netty Version: [netty-buffer=netty-buffer-4.0.23.Final.208198c, netty-codec=netty-codec-4.0.23.Final.208198c, netty-codec-http=netty-codec-http-4.0.23.Final.208198c, netty-codec-socks=netty-codec-socks-4.0.23.Final.208198c, netty-common=netty-common-4.0.23.Final.208198c, netty-handler=netty-handler-4.0.23.Final.208198c, netty-transport=netty-transport-4.0.23.Final.208198c, netty-transport-rxtx=netty-transport-rxtx-4.0.23.Final.208198c, netty-transport-sctp=netty-transport-sctp-4.0.23.Final.208198c, netty-transport-udt=netty-transport-udt-4.0.23.Final.208198c]
09:06:13.331 INFO  o.apache.cassandra.transport.Server - Starting listening for CQL clients on localhost/127.0.0.1:9142...
09:06:13.518 INFO  o.a.cassandra.thrift.ThriftServer - Binding thrift service to localhost/127.0.0.1:9171
09:06:13.534 INFO  o.a.cassandra.thrift.ThriftServer - Listening for thrift clients...
09:06:26.176 ERROR b.hashmade.spark.util.RoadTripUtil - Keyspace roadtrips already exists
com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.exceptions.AlreadyExistsException.copy(AlreadyExistsException.java:85) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.extractCauseFromExecutionException(DefaultResultSetFuture.java:259) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:175) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:52) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:36) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.cassandraunit.CQLDataLoader.load(CQLDataLoader.java:36) ~[cassandra-unit-2.0.2.2.jar:na]
	at blog.hashmade.spark.util.RoadTripUtil.initCassandraWithRoadTrips(RoadTripUtil.java:46) ~[classes/:na]
	at blog.hashmade.spark.DatastaxSparkTest.main(DatastaxSparkTest.java:30) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_25]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_25]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_25]
	at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_25]
	at org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:297) [exec-maven-plugin-1.2.1.jar:na]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_25]
Caused by: com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.exceptions.AlreadyExistsException.copy(AlreadyExistsException.java:85) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:105) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.onSet(DefaultResultSetFuture.java:110) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.RequestHandler.setFinalResult(RequestHandler.java:246) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.RequestHandler.onSet(RequestHandler.java:418) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Connection$Dispatcher.messageReceived(Connection.java:661) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:318) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) ~[netty-3.9.0.Final.jar:na]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_25]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_25]
	... 1 common frames omitted
Caused by: com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:70) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:38) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:168) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:66) ~[netty-3.9.0.Final.jar:na]
	... 21 common frames omitted
09:06:26.660 INFO  org.apache.spark.SecurityManager - Changing view acls to: mdoctor,
09:06:26.660 INFO  org.apache.spark.SecurityManager - Changing modify acls to: mdoctor,
09:06:26.660 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(mdoctor, ); users with modify permissions: Set(mdoctor, )
09:06:27.159 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
09:06:27.222 INFO  Remoting - Starting remoting
09:06:27.331 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:53955]
09:06:27.346 INFO  Remoting - Remoting now listens on addresses: [akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:53955]
09:06:27.362 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53955.
09:06:27.378 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
09:06:27.393 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
09:06:27.409 INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\mdoctor\AppData\Local\Temp\spark-local-20150105090627-1742
09:06:27.440 INFO  org.apache.spark.util.Utils - Successfully started service 'Connection manager for block manager' on port 53958.
09:06:27.440 INFO  o.a.spark.network.ConnectionManager - Bound socket to port 53958 with id = ConnectionManagerId(MDOCTOR.chi.chicorp,53958)
09:06:27.456 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 972.5 MB
09:06:27.456 INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
09:06:27.456 INFO  o.a.s.s.BlockManagerMasterActor - Registering block manager MDOCTOR.chi.chicorp:53958 with 972.5 MB RAM
09:06:27.456 INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
09:06:27.471 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\mdoctor\AppData\Local\Temp\spark-98aeff64-d715-4004-962d-ac9b7aebaf12
09:06:27.487 INFO  org.apache.spark.HttpServer - Starting HTTP Server
09:06:27.549 INFO  org.eclipse.jetty.server.Server - jetty-8.1.14.v20131031
09:06:27.565 INFO  o.e.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:53959
09:06:27.565 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 53959.
09:06:28.048 INFO  org.eclipse.jetty.server.Server - jetty-8.1.14.v20131031
09:06:28.064 INFO  o.e.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
09:06:28.064 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
09:06:28.064 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://MDOCTOR.chi.chicorp:4040
09:06:28.267 INFO  org.apache.spark.util.AkkaUtils - Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:53955/user/HeartbeatReceiver
09:06:28.604 INFO  c.d.s.c.cql.CassandraConnector - Connected to Cassandra cluster: CassClusterDev001
09:06:28.605 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:06:28.605 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:06:28.609 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:06:28.614 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:06:28.622 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:06:28.650 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:06:28.658 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:06:28.658 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:06:28.664 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:06:28.669 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:06:29.141 INFO  c.d.s.c.cql.CassandraConnector - Disconnected from Cassandra cluster: CassClusterDev001
09:06:29.266 INFO  org.apache.spark.SparkContext - Starting job: collect at DatastaxSparkTest.java:80
09:06:29.283 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 1 (groupBy at DatastaxSparkTest.java:66)
09:06:29.285 INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (collect at DatastaxSparkTest.java:80) with 2 output partitions (allowLocal=false)
09:06:29.285 INFO  o.a.spark.scheduler.DAGScheduler - Final stage: Stage 0(collect at DatastaxSparkTest.java:80)
09:06:29.285 INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 1)
09:06:29.291 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(Stage 1)
09:06:29.296 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 1 (MappedRDD[1] at groupBy at DatastaxSparkTest.java:66), which has no missing parents
09:06:29.348 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(6456) called with curMem=0, maxMem=1019782103
09:06:29.350 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 6.3 KB, free 972.5 MB)
09:06:29.376 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 1 (MappedRDD[1] at groupBy at DatastaxSparkTest.java:66)
09:06:29.378 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 2 tasks
09:06:29.399 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 0, localhost, ANY, 25221 bytes)
09:06:29.405 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 0)
09:06:29.442 INFO  org.apache.spark.CacheManager - Partition rdd_0_0 not found, computing it
09:06:29.622 INFO  c.d.s.c.cql.CassandraConnector - Connected to Cassandra cluster: CassClusterDev001
09:06:29.622 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:06:29.626 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:06:29.626 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:06:29.635 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:06:29.644 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:06:29.666 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:06:29.667 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:06:29.676 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:06:29.677 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:06:29.687 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:06:31.900 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=6456, maxMem=1019782103
09:06:31.901 INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_0 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:06:31.902 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_0 in memory on MDOCTOR.chi.chicorp:53958 (size: 16.0 B, free: 972.5 MB)
09:06:31.903 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_0_0
09:06:31.917 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 0). 1385 bytes result sent to driver
09:06:31.921 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 1, localhost, ANY, 25283 bytes)
09:06:31.923 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 1)
09:06:31.934 INFO  org.apache.spark.CacheManager - Partition rdd_0_1 not found, computing it
09:06:31.939 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 0) in 2531 ms on localhost (1/2)
09:06:33.501 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=6472, maxMem=1019782103
09:06:33.502 INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_1 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:06:33.503 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_1 in memory on MDOCTOR.chi.chicorp:53958 (size: 16.0 B, free: 972.5 MB)
09:06:33.518 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_0_1
09:06:33.520 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 1). 1385 bytes result sent to driver
09:06:33.526 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 1) in 1607 ms on localhost (2/2)
09:06:33.526 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
09:06:33.528 INFO  o.a.spark.scheduler.DAGScheduler - Stage 1 (groupBy at DatastaxSparkTest.java:66) finished in 4.142 s
09:06:33.540 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:06:33.540 INFO  o.a.spark.scheduler.DAGScheduler - running: Set()
09:06:33.541 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 0)
09:06:33.541 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:06:33.545 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 0: List()
09:06:33.549 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 0 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72), which is now runnable
09:06:33.554 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2864) called with curMem=6488, maxMem=1019782103
09:06:33.555 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 2.8 KB, free 972.5 MB)
09:06:33.558 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 0 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72)
09:06:33.558 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 2 tasks
09:06:33.559 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 948 bytes)
09:06:33.563 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 2)
09:06:33.566 INFO  org.apache.spark.CacheManager - Partition rdd_4_0 not found, computing it
09:06:33.574 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:06:33.575 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:06:33.576 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 3 ms
09:06:33.587 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=9352, maxMem=1019782103
09:06:33.587 INFO  org.apache.spark.storage.MemoryStore - Block rdd_4_0 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:06:33.588 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_4_0 in memory on MDOCTOR.chi.chicorp:53958 (size: 16.0 B, free: 972.5 MB)
09:06:33.588 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_4_0
09:06:33.589 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 2). 1391 bytes result sent to driver
09:06:33.590 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 948 bytes)
09:06:33.590 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 2) in 31 ms on localhost (1/2)
09:06:33.591 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 3)
09:06:33.593 INFO  org.apache.spark.CacheManager - Partition rdd_4_1 not found, computing it
09:06:33.593 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:06:33.593 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:06:33.593 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:06:33.594 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=9368, maxMem=1019782103
09:06:33.594 INFO  org.apache.spark.storage.MemoryStore - Block rdd_4_1 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:06:33.595 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_4_1 in memory on MDOCTOR.chi.chicorp:53958 (size: 16.0 B, free: 972.5 MB)
09:06:33.595 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_4_1
09:06:33.595 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 3). 1391 bytes result sent to driver
09:06:33.597 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 3) in 8 ms on localhost (2/2)
09:06:33.597 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
09:06:33.597 INFO  o.a.spark.scheduler.DAGScheduler - Stage 0 (collect at DatastaxSparkTest.java:80) finished in 0.038 s
09:06:33.603 INFO  org.apache.spark.SparkContext - Job finished: collect at DatastaxSparkTest.java:80, took 4.335834177 s
09:06:33.604 INFO  b.hashmade.spark.DatastaxSparkTest - Nb RoadTrips by origin
09:06:33.627 INFO  org.apache.spark.SparkContext - Starting job: collect at DatastaxSparkTest.java:103
09:06:33.630 INFO  o.a.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 148 bytes
09:06:33.632 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 4 (mapToPair at DatastaxSparkTest.java:72)
09:06:33.633 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 5 (mapToPair at DatastaxSparkTest.java:86)
09:06:33.633 INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at DatastaxSparkTest.java:103) with 2 output partitions (allowLocal=false)
09:06:33.633 INFO  o.a.spark.scheduler.DAGScheduler - Final stage: Stage 2(collect at DatastaxSparkTest.java:103)
09:06:33.633 INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 5, Stage 4)
09:06:33.635 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(Stage 5, Stage 4)
09:06:33.635 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 4 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72), which has no missing parents
09:06:33.637 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2768) called with curMem=9384, maxMem=1019782103
09:06:33.637 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.7 KB, free 972.5 MB)
09:06:33.638 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 4 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72)
09:06:33.638 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 2 tasks
09:06:33.640 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4, localhost, ANY, 937 bytes)
09:06:33.641 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 5 (MappedRDD[5] at mapToPair at DatastaxSparkTest.java:86), which has no missing parents
09:06:33.641 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
09:06:33.642 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(6464) called with curMem=12152, maxMem=1019782103
09:06:33.642 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 6.3 KB, free 972.5 MB)
09:06:33.644 INFO  o.apache.spark.storage.BlockManager - Found block rdd_4_0 locally
09:06:33.645 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 5 (MappedRDD[5] at mapToPair at DatastaxSparkTest.java:86)
09:06:33.645 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 2 tasks
09:06:33.659 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1874 bytes result sent to driver
09:06:33.660 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 4.0 (TID 5, localhost, ANY, 937 bytes)
09:06:33.661 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 4.0 (TID 5)
09:06:33.662 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 22 ms on localhost (1/2)
09:06:33.665 INFO  o.apache.spark.storage.BlockManager - Found block rdd_4_1 locally
09:06:33.666 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 4.0 (TID 5). 1874 bytes result sent to driver
09:06:33.668 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 6, localhost, ANY, 25221 bytes)
09:06:33.669 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 4.0 (TID 5) in 9 ms on localhost (2/2)
09:06:33.669 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
09:06:33.670 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 6)
09:06:33.674 INFO  o.a.spark.scheduler.DAGScheduler - Stage 4 (mapToPair at DatastaxSparkTest.java:72) finished in 0.034 s
09:06:33.674 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:06:33.674 INFO  o.a.spark.scheduler.DAGScheduler - running: Set(Stage 5)
09:06:33.674 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 2)
09:06:33.674 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:06:33.675 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List(Stage 5)
09:06:33.676 INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_0 locally
09:06:33.677 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 6). 1874 bytes result sent to driver
09:06:33.680 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 7, localhost, ANY, 25283 bytes)
09:06:33.681 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 6) in 14 ms on localhost (1/2)
09:06:33.681 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 7)
09:06:33.689 INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_1 locally
09:06:33.690 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 7). 1874 bytes result sent to driver
09:06:33.691 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 7) in 14 ms on localhost (2/2)
09:06:33.691 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
09:06:33.692 INFO  o.a.spark.scheduler.DAGScheduler - Stage 5 (mapToPair at DatastaxSparkTest.java:86) finished in 0.046 s
09:06:33.692 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:06:33.692 INFO  o.a.spark.scheduler.DAGScheduler - running: Set()
09:06:33.692 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 2)
09:06:33.692 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:06:33.693 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List()
09:06:33.694 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 2 (MappedValuesRDD[10] at mapValues at DatastaxSparkTest.java:98), which is now runnable
09:06:33.695 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3384) called with curMem=18616, maxMem=1019782103
09:06:33.695 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.3 KB, free 972.5 MB)
09:06:33.698 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 2 (MappedValuesRDD[10] at mapValues at DatastaxSparkTest.java:98)
09:06:33.699 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 2 tasks
09:06:33.700 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 8, localhost, PROCESS_LOCAL, 3237 bytes)
09:06:33.700 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 8)
09:06:33.703 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:06:33.703 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:06:33.703 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:06:33.705 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:06:33.705 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:06:33.705 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:06:33.709 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 8). 822 bytes result sent to driver
09:06:33.709 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 9, localhost, PROCESS_LOCAL, 3237 bytes)
09:06:33.710 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 8) in 10 ms on localhost (1/2)
09:06:33.710 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 9)
09:06:33.711 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:06:33.711 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:06:33.711 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:06:33.712 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:06:33.712 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:06:33.712 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:06:33.712 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 9). 822 bytes result sent to driver
09:06:33.713 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 9) in 4 ms on localhost (2/2)
09:06:33.713 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
09:06:33.713 INFO  o.a.spark.scheduler.DAGScheduler - Stage 2 (collect at DatastaxSparkTest.java:103) finished in 0.014 s
09:06:33.714 INFO  org.apache.spark.SparkContext - Job finished: collect at DatastaxSparkTest.java:103, took 0.08653893 s
09:06:33.714 INFO  b.hashmade.spark.DatastaxSparkTest - Average distance by origin
09:06:33.811 INFO  c.d.s.c.cql.CassandraConnector - Disconnected from Cassandra cluster: CassClusterDev001
09:10:12.221 INFO  o.a.cassandra.thrift.ThriftServer - Stop listening to thrift clients
09:10:12.253 INFO  o.apache.cassandra.transport.Server - Stop listening for CQL clients
09:10:12.253 INFO  org.apache.cassandra.gms.Gossiper - Announcing shutdown
09:10:14.265 INFO  o.a.cassandra.net.MessagingService - Waiting for messaging service to quiesce
09:10:14.265 INFO  o.a.cassandra.net.MessagingService - MessagingService has terminated the accept() thread
09:10:27.822 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:10:27.916 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:10:28.212 INFO  o.a.c.config.DatabaseDescriptor - DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
09:10:28.243 INFO  o.a.c.config.DatabaseDescriptor - Global memtable on-heap threshold is enabled at 450MB
09:10:28.243 INFO  o.a.c.config.DatabaseDescriptor - Global memtable off-heap threshold is enabled at 450MB
09:10:28.493 WARN  o.a.c.config.DatabaseDescriptor - Please rename encryption_options as server_encryption_options in the yaml
09:10:28.758 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:10:28.789 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:10:28.867 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:10:28.883 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:10:30.537 INFO  o.a.c.config.DatabaseDescriptor - Couldn't detect any schema definitions in local storage.
09:10:30.552 INFO  o.a.c.config.DatabaseDescriptor - To create keyspaces and column families, see 'help create' in cqlsh.
09:10:30.928 INFO  o.a.c.io.sstable.IndexSummaryManager - Initializing index summary manager with a memory pool size of 14 MB and a resize interval of 60 minutes
09:10:30.975 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:10:31.006 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:10:31.162 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:10:31.177 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:10:31.302 INFO  o.a.cassandra.net.MessagingService - Starting Messaging Service on port 7010
09:10:31.333 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:10:31.333 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:10:31.443 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:10:31.443 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:10:31.552 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:10:31.567 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:10:32.207 INFO  o.apache.cassandra.transport.Server - Using Netty Version: [netty-buffer=netty-buffer-4.0.23.Final.208198c, netty-codec=netty-codec-4.0.23.Final.208198c, netty-codec-http=netty-codec-http-4.0.23.Final.208198c, netty-codec-socks=netty-codec-socks-4.0.23.Final.208198c, netty-common=netty-common-4.0.23.Final.208198c, netty-handler=netty-handler-4.0.23.Final.208198c, netty-transport=netty-transport-4.0.23.Final.208198c, netty-transport-rxtx=netty-transport-rxtx-4.0.23.Final.208198c, netty-transport-sctp=netty-transport-sctp-4.0.23.Final.208198c, netty-transport-udt=netty-transport-udt-4.0.23.Final.208198c]
09:10:32.223 INFO  o.apache.cassandra.transport.Server - Starting listening for CQL clients on localhost/127.0.0.1:9142...
09:10:32.488 INFO  o.a.cassandra.thrift.ThriftServer - Binding thrift service to localhost/127.0.0.1:9171
09:10:32.503 INFO  o.a.cassandra.thrift.ThriftServer - Listening for thrift clients...
09:10:45.397 ERROR b.hashmade.spark.util.RoadTripUtil - Keyspace roadtrips already exists
com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.exceptions.AlreadyExistsException.copy(AlreadyExistsException.java:85) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.extractCauseFromExecutionException(DefaultResultSetFuture.java:259) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:175) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:52) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:36) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.cassandraunit.CQLDataLoader.load(CQLDataLoader.java:36) ~[cassandra-unit-2.0.2.2.jar:na]
	at blog.hashmade.spark.util.RoadTripUtil.initCassandraWithRoadTrips(RoadTripUtil.java:46) ~[classes/:na]
	at blog.hashmade.spark.DatastaxSparkTest.main(DatastaxSparkTest.java:30) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_25]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_25]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_25]
	at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_25]
	at org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:297) [exec-maven-plugin-1.2.1.jar:na]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_25]
Caused by: com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.exceptions.AlreadyExistsException.copy(AlreadyExistsException.java:85) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:105) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.onSet(DefaultResultSetFuture.java:110) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.RequestHandler.setFinalResult(RequestHandler.java:246) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.RequestHandler.onSet(RequestHandler.java:418) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Connection$Dispatcher.messageReceived(Connection.java:661) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:318) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) ~[netty-3.9.0.Final.jar:na]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_25]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_25]
	... 1 common frames omitted
Caused by: com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:70) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:38) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:168) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:66) ~[netty-3.9.0.Final.jar:na]
	... 21 common frames omitted
09:10:45.849 INFO  org.apache.spark.SecurityManager - Changing view acls to: mdoctor,
09:10:45.849 INFO  org.apache.spark.SecurityManager - Changing modify acls to: mdoctor,
09:10:45.865 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(mdoctor, ); users with modify permissions: Set(mdoctor, )
09:10:46.177 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
09:10:46.223 INFO  Remoting - Starting remoting
09:10:46.301 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54100]
09:10:46.317 INFO  Remoting - Remoting now listens on addresses: [akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54100]
09:10:46.317 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54100.
09:10:46.348 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
09:10:46.348 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
09:10:46.379 INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\mdoctor\AppData\Local\Temp\spark-local-20150105091046-e3cc
09:10:46.411 INFO  org.apache.spark.util.Utils - Successfully started service 'Connection manager for block manager' on port 54103.
09:10:46.411 INFO  o.a.spark.network.ConnectionManager - Bound socket to port 54103 with id = ConnectionManagerId(MDOCTOR.chi.chicorp,54103)
09:10:46.426 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 972.5 MB
09:10:46.426 INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
09:10:46.426 INFO  o.a.s.s.BlockManagerMasterActor - Registering block manager MDOCTOR.chi.chicorp:54103 with 972.5 MB RAM
09:10:46.426 INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
09:10:46.442 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\mdoctor\AppData\Local\Temp\spark-aa7d1644-4e94-430d-b35e-4d1f34062a05
09:10:46.457 INFO  org.apache.spark.HttpServer - Starting HTTP Server
09:10:46.520 INFO  org.eclipse.jetty.server.Server - jetty-8.1.14.v20131031
09:10:46.535 INFO  o.e.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:54104
09:10:46.535 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 54104.
09:10:47.019 INFO  org.eclipse.jetty.server.Server - jetty-8.1.14.v20131031
09:10:47.035 INFO  o.e.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
09:10:47.035 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
09:10:47.050 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://MDOCTOR.chi.chicorp:4040
09:10:47.253 INFO  org.apache.spark.util.AkkaUtils - Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54100/user/HeartbeatReceiver
09:10:47.585 INFO  c.d.s.c.cql.CassandraConnector - Connected to Cassandra cluster: CassClusterDev001
09:10:47.591 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:10:47.591 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:10:47.591 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:10:47.600 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:10:47.600 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:10:47.632 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:10:47.632 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:10:47.632 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:10:47.642 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:10:47.648 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:10:48.053 INFO  c.d.s.c.cql.CassandraConnector - Disconnected from Cassandra cluster: CassClusterDev001
09:10:48.354 INFO  org.apache.spark.SparkContext - Starting job: collect at DatastaxSparkTest.java:80
09:10:48.373 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 1 (groupBy at DatastaxSparkTest.java:66)
09:10:48.375 INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (collect at DatastaxSparkTest.java:80) with 2 output partitions (allowLocal=false)
09:10:48.376 INFO  o.a.spark.scheduler.DAGScheduler - Final stage: Stage 0(collect at DatastaxSparkTest.java:80)
09:10:48.376 INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 1)
09:10:48.381 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(Stage 1)
09:10:48.386 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 1 (MappedRDD[1] at groupBy at DatastaxSparkTest.java:66), which has no missing parents
09:10:48.438 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(6456) called with curMem=0, maxMem=1019782103
09:10:48.440 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 6.3 KB, free 972.5 MB)
09:10:48.464 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 1 (MappedRDD[1] at groupBy at DatastaxSparkTest.java:66)
09:10:48.465 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 2 tasks
09:10:48.489 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 0, localhost, ANY, 25221 bytes)
09:10:48.495 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 0)
09:10:48.534 INFO  org.apache.spark.CacheManager - Partition rdd_0_0 not found, computing it
09:10:48.711 INFO  c.d.s.c.cql.CassandraConnector - Connected to Cassandra cluster: CassClusterDev001
09:10:48.712 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:10:48.715 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:10:48.716 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:10:48.723 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:10:48.732 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:10:48.758 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:10:48.758 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:10:48.760 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:10:48.768 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:10:48.774 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:10:51.064 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=6456, maxMem=1019782103
09:10:51.065 INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_0 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:10:51.066 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_0 in memory on MDOCTOR.chi.chicorp:54103 (size: 16.0 B, free: 972.5 MB)
09:10:51.067 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_0_0
09:10:51.083 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 0). 1385 bytes result sent to driver
09:10:51.089 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 1, localhost, ANY, 25283 bytes)
09:10:51.092 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 0) in 2610 ms on localhost (1/2)
09:10:51.094 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 1)
09:10:51.100 INFO  org.apache.spark.CacheManager - Partition rdd_0_1 not found, computing it
09:10:53.322 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=6472, maxMem=1019782103
09:10:53.323 INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_1 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:10:53.324 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_1 in memory on MDOCTOR.chi.chicorp:54103 (size: 16.0 B, free: 972.5 MB)
09:10:53.324 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_0_1
09:10:53.325 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 1). 1385 bytes result sent to driver
09:10:53.336 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 1) in 2252 ms on localhost (2/2)
09:10:53.337 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
09:10:53.340 INFO  o.a.spark.scheduler.DAGScheduler - Stage 1 (groupBy at DatastaxSparkTest.java:66) finished in 4.867 s
09:10:53.341 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:10:53.342 INFO  o.a.spark.scheduler.DAGScheduler - running: Set()
09:10:53.342 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 0)
09:10:53.343 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:10:53.349 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 0: List()
09:10:53.351 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 0 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72), which is now runnable
09:10:53.352 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2864) called with curMem=6488, maxMem=1019782103
09:10:53.352 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 2.8 KB, free 972.5 MB)
09:10:53.354 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 0 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72)
09:10:53.354 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 2 tasks
09:10:53.355 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 948 bytes)
09:10:53.355 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 2)
09:10:53.357 INFO  org.apache.spark.CacheManager - Partition rdd_4_0 not found, computing it
09:10:53.362 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:10:53.364 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:10:53.365 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 3 ms
09:10:53.376 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=9352, maxMem=1019782103
09:10:53.376 INFO  org.apache.spark.storage.MemoryStore - Block rdd_4_0 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:10:53.377 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_4_0 in memory on MDOCTOR.chi.chicorp:54103 (size: 16.0 B, free: 972.5 MB)
09:10:53.377 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_4_0
09:10:53.378 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 2). 1391 bytes result sent to driver
09:10:53.379 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 948 bytes)
09:10:53.380 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 2) in 25 ms on localhost (1/2)
09:10:53.381 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 3)
09:10:53.384 INFO  org.apache.spark.CacheManager - Partition rdd_4_1 not found, computing it
09:10:53.385 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:10:53.385 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:10:53.385 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:10:53.386 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=9368, maxMem=1019782103
09:10:53.386 INFO  org.apache.spark.storage.MemoryStore - Block rdd_4_1 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:10:53.386 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_4_1 in memory on MDOCTOR.chi.chicorp:54103 (size: 16.0 B, free: 972.5 MB)
09:10:53.387 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_4_1
09:10:53.388 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 3). 1391 bytes result sent to driver
09:10:53.390 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 3) in 12 ms on localhost (2/2)
09:10:53.390 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
09:10:53.390 INFO  o.a.spark.scheduler.DAGScheduler - Stage 0 (collect at DatastaxSparkTest.java:80) finished in 0.035 s
09:10:53.395 INFO  org.apache.spark.SparkContext - Job finished: collect at DatastaxSparkTest.java:80, took 5.040061777 s
09:10:53.397 INFO  b.hashmade.spark.DatastaxSparkTest - Nb RoadTrips by origin
09:10:53.433 INFO  org.apache.spark.SparkContext - Starting job: collect at DatastaxSparkTest.java:103
09:10:53.436 INFO  o.a.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 148 bytes
09:10:53.439 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 4 (mapToPair at DatastaxSparkTest.java:72)
09:10:53.439 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 5 (mapToPair at DatastaxSparkTest.java:86)
09:10:53.440 INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at DatastaxSparkTest.java:103) with 2 output partitions (allowLocal=false)
09:10:53.440 INFO  o.a.spark.scheduler.DAGScheduler - Final stage: Stage 2(collect at DatastaxSparkTest.java:103)
09:10:53.440 INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 5, Stage 4)
09:10:53.441 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(Stage 5, Stage 4)
09:10:53.441 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 4 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72), which has no missing parents
09:10:53.443 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2768) called with curMem=9384, maxMem=1019782103
09:10:53.443 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.7 KB, free 972.5 MB)
09:10:53.444 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 4 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72)
09:10:53.444 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 2 tasks
09:10:53.446 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4, localhost, ANY, 937 bytes)
09:10:53.446 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
09:10:53.447 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 5 (MappedRDD[5] at mapToPair at DatastaxSparkTest.java:86), which has no missing parents
09:10:53.450 INFO  o.apache.spark.storage.BlockManager - Found block rdd_4_0 locally
09:10:53.459 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1874 bytes result sent to driver
09:10:53.460 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 4.0 (TID 5, localhost, ANY, 937 bytes)
09:10:53.460 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(6464) called with curMem=12152, maxMem=1019782103
09:10:53.460 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 6.3 KB, free 972.5 MB)
09:10:53.461 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 15 ms on localhost (1/2)
09:10:53.461 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 4.0 (TID 5)
09:10:53.464 INFO  o.apache.spark.storage.BlockManager - Found block rdd_4_1 locally
09:10:53.465 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 4.0 (TID 5). 1874 bytes result sent to driver
09:10:53.467 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 5 (MappedRDD[5] at mapToPair at DatastaxSparkTest.java:86)
09:10:53.467 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 2 tasks
09:10:53.470 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 6, localhost, ANY, 25221 bytes)
09:10:53.471 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 6)
09:10:53.476 INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_0 locally
09:10:53.476 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 6). 1874 bytes result sent to driver
09:10:53.477 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 4.0 (TID 5) in 12 ms on localhost (2/2)
09:10:53.477 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
09:10:53.480 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 7, localhost, ANY, 25283 bytes)
09:10:53.481 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 6) in 13 ms on localhost (1/2)
09:10:53.481 INFO  o.a.spark.scheduler.DAGScheduler - Stage 4 (mapToPair at DatastaxSparkTest.java:72) finished in 0.036 s
09:10:53.481 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:10:53.481 INFO  o.a.spark.scheduler.DAGScheduler - running: Set(Stage 5)
09:10:53.481 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 2)
09:10:53.481 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:10:53.481 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 7)
09:10:53.487 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List(Stage 5)
09:10:53.490 INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_1 locally
09:10:53.491 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 7). 1874 bytes result sent to driver
09:10:53.493 INFO  o.a.spark.scheduler.DAGScheduler - Stage 5 (mapToPair at DatastaxSparkTest.java:86) finished in 0.025 s
09:10:53.493 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:10:53.493 INFO  o.a.spark.scheduler.DAGScheduler - running: Set()
09:10:53.493 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 2)
09:10:53.493 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:10:53.493 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 7) in 15 ms on localhost (2/2)
09:10:53.493 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
09:10:53.495 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List()
09:10:53.495 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 2 (MappedValuesRDD[10] at mapValues at DatastaxSparkTest.java:98), which is now runnable
09:10:53.496 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3384) called with curMem=18616, maxMem=1019782103
09:10:53.497 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.3 KB, free 972.5 MB)
09:10:53.501 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 2 (MappedValuesRDD[10] at mapValues at DatastaxSparkTest.java:98)
09:10:53.501 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 2 tasks
09:10:53.502 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 8, localhost, PROCESS_LOCAL, 3237 bytes)
09:10:53.502 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 8)
09:10:53.505 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:10:53.505 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:10:53.505 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:10:53.506 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:10:53.507 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:10:53.507 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 1 ms
09:10:53.513 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 8). 822 bytes result sent to driver
09:10:53.513 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 9, localhost, PROCESS_LOCAL, 3237 bytes)
09:10:53.513 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 9)
09:10:53.514 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 8) in 12 ms on localhost (1/2)
09:10:53.515 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:10:53.515 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:10:53.515 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:10:53.516 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:10:53.516 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:10:53.516 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:10:53.517 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 9). 822 bytes result sent to driver
09:10:53.518 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 9) in 5 ms on localhost (2/2)
09:10:53.518 INFO  o.a.spark.scheduler.DAGScheduler - Stage 2 (collect at DatastaxSparkTest.java:103) finished in 0.016 s
09:10:53.518 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
09:10:53.519 INFO  org.apache.spark.SparkContext - Job finished: collect at DatastaxSparkTest.java:103, took 0.085634612 s
09:10:53.519 INFO  b.hashmade.spark.DatastaxSparkTest - Average distance by origin
09:10:53.809 INFO  c.d.s.c.cql.CassandraConnector - Disconnected from Cassandra cluster: CassClusterDev001
09:14:51.425 INFO  o.a.cassandra.thrift.ThriftServer - Stop listening to thrift clients
09:14:51.470 INFO  o.apache.cassandra.transport.Server - Stop listening for CQL clients
09:14:51.476 INFO  org.apache.cassandra.gms.Gossiper - Announcing shutdown
09:14:53.480 INFO  o.a.cassandra.net.MessagingService - Waiting for messaging service to quiesce
09:14:53.486 INFO  o.a.cassandra.net.MessagingService - MessagingService has terminated the accept() thread
09:15:28.906 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:15:29.025 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:15:29.310 INFO  o.a.c.config.DatabaseDescriptor - DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
09:15:29.331 INFO  o.a.c.config.DatabaseDescriptor - Global memtable on-heap threshold is enabled at 450MB
09:15:29.335 INFO  o.a.c.config.DatabaseDescriptor - Global memtable off-heap threshold is enabled at 450MB
09:15:29.478 WARN  o.a.c.config.DatabaseDescriptor - Please rename encryption_options as server_encryption_options in the yaml
09:15:29.680 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:15:29.695 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:15:29.774 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:15:29.789 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:15:31.120 INFO  o.a.c.config.DatabaseDescriptor - Couldn't detect any schema definitions in local storage.
09:15:31.127 INFO  o.a.c.config.DatabaseDescriptor - To create keyspaces and column families, see 'help create' in cqlsh.
09:15:31.402 INFO  o.a.c.io.sstable.IndexSummaryManager - Initializing index summary manager with a memory pool size of 14 MB and a resize interval of 60 minutes
09:15:31.430 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:15:31.441 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:15:31.554 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:15:31.577 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:15:31.679 INFO  o.a.cassandra.net.MessagingService - Starting Messaging Service on port 7010
09:15:31.704 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:15:31.750 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:15:31.837 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:15:31.848 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:15:31.936 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:15:31.956 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:15:32.765 INFO  o.apache.cassandra.transport.Server - Using Netty Version: [netty-buffer=netty-buffer-4.0.23.Final.208198c, netty-codec=netty-codec-4.0.23.Final.208198c, netty-codec-http=netty-codec-http-4.0.23.Final.208198c, netty-codec-socks=netty-codec-socks-4.0.23.Final.208198c, netty-common=netty-common-4.0.23.Final.208198c, netty-handler=netty-handler-4.0.23.Final.208198c, netty-transport=netty-transport-4.0.23.Final.208198c, netty-transport-rxtx=netty-transport-rxtx-4.0.23.Final.208198c, netty-transport-sctp=netty-transport-sctp-4.0.23.Final.208198c, netty-transport-udt=netty-transport-udt-4.0.23.Final.208198c]
09:15:32.792 INFO  o.apache.cassandra.transport.Server - Starting listening for CQL clients on localhost/127.0.0.1:9142...
09:15:33.024 INFO  o.a.cassandra.thrift.ThriftServer - Binding thrift service to localhost/127.0.0.1:9171
09:15:33.040 INFO  o.a.cassandra.thrift.ThriftServer - Listening for thrift clients...
09:15:50.766 INFO  org.apache.spark.SecurityManager - Changing view acls to: mdoctor,
09:15:50.771 INFO  org.apache.spark.SecurityManager - Changing modify acls to: mdoctor,
09:15:50.776 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(mdoctor, ); users with modify permissions: Set(mdoctor, )
09:15:51.084 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
09:15:51.120 INFO  Remoting - Starting remoting
09:15:51.210 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54276]
09:15:51.219 INFO  Remoting - Remoting now listens on addresses: [akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54276]
09:15:51.231 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54276.
09:15:51.253 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
09:15:51.265 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
09:15:51.286 INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\mdoctor\AppData\Local\Temp\spark-local-20150105091551-fdb8
09:15:51.315 INFO  org.apache.spark.util.Utils - Successfully started service 'Connection manager for block manager' on port 54279.
09:15:51.324 INFO  o.a.spark.network.ConnectionManager - Bound socket to port 54279 with id = ConnectionManagerId(MDOCTOR.chi.chicorp,54279)
09:15:51.333 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 972.5 MB
09:15:51.337 INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
09:15:51.338 INFO  o.a.s.s.BlockManagerMasterActor - Registering block manager MDOCTOR.chi.chicorp:54279 with 972.5 MB RAM
09:15:51.339 INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
09:15:51.351 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\mdoctor\AppData\Local\Temp\spark-ca9dbb17-363b-455d-a086-41235371e66c
09:15:51.364 INFO  org.apache.spark.HttpServer - Starting HTTP Server
09:15:51.420 INFO  org.eclipse.jetty.server.Server - jetty-8.1.14.v20131031
09:15:51.436 INFO  o.e.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:54280
09:15:51.440 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 54280.
09:15:51.887 INFO  org.eclipse.jetty.server.Server - jetty-8.1.14.v20131031
09:15:51.898 INFO  o.e.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
09:15:51.902 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
09:15:51.910 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://MDOCTOR.chi.chicorp:4040
09:15:52.127 INFO  org.apache.spark.util.AkkaUtils - Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54276/user/HeartbeatReceiver
09:15:52.483 INFO  c.d.s.c.cql.CassandraConnector - Connected to Cassandra cluster: CassClusterDev001
09:15:52.489 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:15:52.489 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:15:52.492 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:15:52.493 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:15:52.505 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:15:52.527 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:15:52.527 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:15:52.538 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:15:52.538 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:15:52.543 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:15:52.992 INFO  c.d.s.c.cql.CassandraConnector - Disconnected from Cassandra cluster: CassClusterDev001
09:15:53.150 INFO  org.apache.spark.SparkContext - Starting job: collect at DatastaxSparkTest.java:80
09:15:53.165 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 1 (groupBy at DatastaxSparkTest.java:66)
09:15:53.166 INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (collect at DatastaxSparkTest.java:80) with 2 output partitions (allowLocal=false)
09:15:53.167 INFO  o.a.spark.scheduler.DAGScheduler - Final stage: Stage 0(collect at DatastaxSparkTest.java:80)
09:15:53.167 INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 1)
09:15:53.171 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(Stage 1)
09:15:53.180 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 1 (MappedRDD[1] at groupBy at DatastaxSparkTest.java:66), which has no missing parents
09:15:53.231 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(6456) called with curMem=0, maxMem=1019782103
09:15:53.233 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 6.3 KB, free 972.5 MB)
09:15:53.259 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 1 (MappedRDD[1] at groupBy at DatastaxSparkTest.java:66)
09:15:53.260 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 2 tasks
09:15:53.281 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 0, localhost, ANY, 25221 bytes)
09:15:53.287 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 0)
09:15:53.318 INFO  org.apache.spark.CacheManager - Partition rdd_0_0 not found, computing it
09:15:53.534 INFO  c.d.s.c.cql.CassandraConnector - Connected to Cassandra cluster: CassClusterDev001
09:15:53.534 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:15:53.534 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:15:53.538 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:15:53.542 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:15:53.548 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:15:53.581 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:15:53.584 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:15:53.584 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:15:53.585 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:15:53.595 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:15:56.787 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2372497) called with curMem=6456, maxMem=1019782103
09:15:56.788 INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_0 stored as values in memory (estimated size 2.3 MB, free 970.3 MB)
09:15:56.789 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_0 in memory on MDOCTOR.chi.chicorp:54279 (size: 2.3 MB, free: 970.3 MB)
09:15:56.792 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_0_0
09:15:56.964 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 0). 1385 bytes result sent to driver
09:15:56.964 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 1, localhost, ANY, 25283 bytes)
09:15:56.965 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 1)
09:15:56.968 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 0) in 3692 ms on localhost (1/2)
09:15:56.975 INFO  org.apache.spark.CacheManager - Partition rdd_0_1 not found, computing it
09:15:59.278 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2549804) called with curMem=2378953, maxMem=1019782103
09:15:59.279 INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_1 stored as values in memory (estimated size 2.4 MB, free 967.8 MB)
09:15:59.282 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_1 in memory on MDOCTOR.chi.chicorp:54279 (size: 2.4 MB, free: 967.8 MB)
09:15:59.283 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_0_1
09:15:59.405 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 1). 1385 bytes result sent to driver
09:15:59.415 INFO  o.a.spark.scheduler.DAGScheduler - Stage 1 (groupBy at DatastaxSparkTest.java:66) finished in 6.147 s
09:15:59.414 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 1) in 2453 ms on localhost (2/2)
09:15:59.416 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:15:59.418 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
09:15:59.419 INFO  o.a.spark.scheduler.DAGScheduler - running: Set()
09:15:59.420 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 0)
09:15:59.420 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:15:59.424 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 0: List()
09:15:59.427 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 0 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72), which is now runnable
09:15:59.428 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2864) called with curMem=4928757, maxMem=1019782103
09:15:59.429 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 2.8 KB, free 967.8 MB)
09:15:59.433 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 0 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72)
09:15:59.433 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 2 tasks
09:15:59.434 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 948 bytes)
09:15:59.434 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 2)
09:15:59.437 INFO  org.apache.spark.CacheManager - Partition rdd_4_0 not found, computing it
09:15:59.444 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:15:59.446 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 2 non-empty blocks out of 2 blocks
09:15:59.447 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 4 ms
09:15:59.664 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3080) called with curMem=4931621, maxMem=1019782103
09:15:59.664 INFO  org.apache.spark.storage.MemoryStore - Block rdd_4_0 stored as values in memory (estimated size 3.0 KB, free 967.8 MB)
09:15:59.665 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_4_0 in memory on MDOCTOR.chi.chicorp:54279 (size: 3.0 KB, free: 967.8 MB)
09:15:59.665 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_4_0
09:15:59.666 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 2). 2313 bytes result sent to driver
09:15:59.667 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 948 bytes)
09:15:59.668 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 3)
09:15:59.668 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 2) in 234 ms on localhost (1/2)
09:15:59.669 INFO  org.apache.spark.CacheManager - Partition rdd_4_1 not found, computing it
09:15:59.670 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:15:59.670 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 2 non-empty blocks out of 2 blocks
09:15:59.670 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 1 ms
09:15:59.714 INFO  c.d.s.c.cql.CassandraConnector - Disconnected from Cassandra cluster: CassClusterDev001
09:15:59.874 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3064) called with curMem=4934701, maxMem=1019782103
09:15:59.874 INFO  org.apache.spark.storage.MemoryStore - Block rdd_4_1 stored as values in memory (estimated size 3.0 KB, free 967.8 MB)
09:15:59.874 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_4_1 in memory on MDOCTOR.chi.chicorp:54279 (size: 3.0 KB, free: 967.8 MB)
09:15:59.874 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_4_1
09:15:59.875 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 3). 2279 bytes result sent to driver
09:15:59.876 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 3) in 209 ms on localhost (2/2)
09:15:59.876 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
09:15:59.877 INFO  o.a.spark.scheduler.DAGScheduler - Stage 0 (collect at DatastaxSparkTest.java:80) finished in 0.443 s
09:15:59.884 INFO  org.apache.spark.SparkContext - Job finished: collect at DatastaxSparkTest.java:80, took 6.733515869 s
09:15:59.887 INFO  b.hashmade.spark.DatastaxSparkTest - Nb RoadTrips by origin
09:15:59.889 INFO  b.hashmade.spark.DatastaxSparkTest - Albuquerque : 61
09:15:59.892 INFO  b.hashmade.spark.DatastaxSparkTest - Raleigh/Durham : 62
09:15:59.896 INFO  b.hashmade.spark.DatastaxSparkTest - Columbus : 31
09:15:59.901 INFO  b.hashmade.spark.DatastaxSparkTest - Washington : 358
09:15:59.903 INFO  b.hashmade.spark.DatastaxSparkTest - Seattle : 31
09:15:59.909 INFO  b.hashmade.spark.DatastaxSparkTest - Salt Lake City : 31
09:15:59.911 INFO  b.hashmade.spark.DatastaxSparkTest - Newark : 61
09:15:59.914 INFO  b.hashmade.spark.DatastaxSparkTest - El Paso : 31
09:15:59.917 INFO  b.hashmade.spark.DatastaxSparkTest - Ontario : 36
09:15:59.920 INFO  b.hashmade.spark.DatastaxSparkTest - Hartford : 31
09:15:59.922 INFO  b.hashmade.spark.DatastaxSparkTest - San Antonio : 176
09:15:59.925 INFO  b.hashmade.spark.DatastaxSparkTest - Omaha : 57
09:15:59.929 INFO  b.hashmade.spark.DatastaxSparkTest - Las Vegas : 93
09:15:59.932 INFO  b.hashmade.spark.DatastaxSparkTest - Portland : 9
09:15:59.935 INFO  b.hashmade.spark.DatastaxSparkTest - Austin : 194
09:15:59.939 INFO  b.hashmade.spark.DatastaxSparkTest - Charlotte : 31
09:15:59.942 INFO  b.hashmade.spark.DatastaxSparkTest - Houston : 58
09:15:59.948 INFO  b.hashmade.spark.DatastaxSparkTest - Kansas City : 93
09:15:59.950 INFO  b.hashmade.spark.DatastaxSparkTest - Chicago : 1108
09:15:59.954 INFO  b.hashmade.spark.DatastaxSparkTest - Palm Springs : 31
09:15:59.957 INFO  b.hashmade.spark.DatastaxSparkTest - Honolulu : 164
09:15:59.961 INFO  b.hashmade.spark.DatastaxSparkTest - San Juan : 62
09:15:59.964 INFO  b.hashmade.spark.DatastaxSparkTest - Fort Lauderdale : 31
09:15:59.967 INFO  b.hashmade.spark.DatastaxSparkTest - Louisville : 1
09:15:59.971 INFO  b.hashmade.spark.DatastaxSparkTest - San Francisco : 362
09:15:59.974 INFO  b.hashmade.spark.DatastaxSparkTest - San Diego : 159
09:15:59.977 INFO  b.hashmade.spark.DatastaxSparkTest - Mission/McAllen/Edinburg : 30
09:15:59.982 INFO  b.hashmade.spark.DatastaxSparkTest - West Palm Beach/Palm Beach : 62
09:15:59.988 INFO  b.hashmade.spark.DatastaxSparkTest - Fayetteville : 31
09:15:59.991 INFO  b.hashmade.spark.DatastaxSparkTest - Wichita : 62
09:15:59.993 INFO  b.hashmade.spark.DatastaxSparkTest - Memphis : 24
09:15:59.996 INFO  b.hashmade.spark.DatastaxSparkTest - Kahului : 93
09:15:59.999 INFO  b.hashmade.spark.DatastaxSparkTest - St. Louis : 204
09:16:00.002 INFO  b.hashmade.spark.DatastaxSparkTest - Orlando : 154
09:16:00.005 INFO  b.hashmade.spark.DatastaxSparkTest - Oklahoma City : 31
09:16:00.007 INFO  b.hashmade.spark.DatastaxSparkTest - Phoenix : 124
09:16:00.010 INFO  b.hashmade.spark.DatastaxSparkTest - Santa Ana : 33
09:16:00.013 INFO  b.hashmade.spark.DatastaxSparkTest - Baltimore : 27
09:16:00.015 INFO  b.hashmade.spark.DatastaxSparkTest - Burbank : 8
09:16:00.018 INFO  b.hashmade.spark.DatastaxSparkTest - Miami : 773
09:16:00.021 INFO  b.hashmade.spark.DatastaxSparkTest - Kona : 31
09:16:00.023 INFO  b.hashmade.spark.DatastaxSparkTest - New York : 978
09:16:00.027 INFO  b.hashmade.spark.DatastaxSparkTest - Norfolk : 50
09:16:00.030 INFO  b.hashmade.spark.DatastaxSparkTest - San Jose : 57
09:16:00.033 INFO  b.hashmade.spark.DatastaxSparkTest - Philadelphia : 8
09:16:00.036 INFO  b.hashmade.spark.DatastaxSparkTest - Minneapolis : 30
09:16:00.039 INFO  b.hashmade.spark.DatastaxSparkTest - Lihue : 42
09:16:00.042 INFO  b.hashmade.spark.DatastaxSparkTest - Tampa : 124
09:16:00.045 INFO  b.hashmade.spark.DatastaxSparkTest - Fort Myers : 31
09:16:00.048 INFO  b.hashmade.spark.DatastaxSparkTest - Dayton : 31
09:16:00.050 INFO  b.hashmade.spark.DatastaxSparkTest - Colorado Springs : 31
09:16:00.053 INFO  b.hashmade.spark.DatastaxSparkTest - Boston : 212
09:16:00.056 INFO  b.hashmade.spark.DatastaxSparkTest - Tulsa : 62
09:16:00.058 INFO  b.hashmade.spark.DatastaxSparkTest - Los Angeles : 957
09:16:00.061 INFO  b.hashmade.spark.DatastaxSparkTest - Atlanta : 31
09:16:00.064 INFO  b.hashmade.spark.DatastaxSparkTest - Indianapolis : 1
09:16:00.066 INFO  b.hashmade.spark.DatastaxSparkTest - Dallas/Fort Worth : 2275
09:16:00.071 INFO  b.hashmade.spark.DatastaxSparkTest - Charlotte Amalie : 31
09:16:00.098 INFO  org.apache.spark.SparkContext - Starting job: collect at DatastaxSparkTest.java:103
09:16:00.100 INFO  o.a.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 153 bytes
09:16:00.102 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 4 (mapToPair at DatastaxSparkTest.java:72)
09:16:00.103 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 5 (mapToPair at DatastaxSparkTest.java:86)
09:16:00.103 INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at DatastaxSparkTest.java:103) with 2 output partitions (allowLocal=false)
09:16:00.103 INFO  o.a.spark.scheduler.DAGScheduler - Final stage: Stage 2(collect at DatastaxSparkTest.java:103)
09:16:00.103 INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 5, Stage 4)
09:16:00.104 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(Stage 5, Stage 4)
09:16:00.105 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 4 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72), which has no missing parents
09:16:00.106 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2768) called with curMem=4937765, maxMem=1019782103
09:16:00.106 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.7 KB, free 967.8 MB)
09:16:00.107 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 4 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72)
09:16:00.107 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 2 tasks
09:16:00.109 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4, localhost, ANY, 937 bytes)
09:16:00.109 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
09:16:00.109 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 5 (MappedRDD[5] at mapToPair at DatastaxSparkTest.java:86), which has no missing parents
09:16:00.110 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(6464) called with curMem=4940533, maxMem=1019782103
09:16:00.110 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 6.3 KB, free 967.8 MB)
09:16:00.112 INFO  o.apache.spark.storage.BlockManager - Found block rdd_4_0 locally
09:16:00.113 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 5 (MappedRDD[5] at mapToPair at DatastaxSparkTest.java:86)
09:16:00.113 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 2 tasks
09:16:00.127 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1874 bytes result sent to driver
09:16:00.127 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 4.0 (TID 5, localhost, ANY, 937 bytes)
09:16:00.129 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 19 ms on localhost (1/2)
09:16:00.129 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 4.0 (TID 5)
09:16:00.132 INFO  o.apache.spark.storage.BlockManager - Found block rdd_4_1 locally
09:16:00.133 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 4.0 (TID 5). 1874 bytes result sent to driver
09:16:00.135 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 6, localhost, ANY, 25221 bytes)
09:16:00.136 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 4.0 (TID 5) in 9 ms on localhost (2/2)
09:16:00.136 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
09:16:00.136 INFO  o.a.spark.scheduler.DAGScheduler - Stage 4 (mapToPair at DatastaxSparkTest.java:72) finished in 0.027 s
09:16:00.136 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:16:00.136 INFO  o.a.spark.scheduler.DAGScheduler - running: Set(Stage 5)
09:16:00.136 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 2)
09:16:00.136 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:16:00.137 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 6)
09:16:00.138 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List(Stage 5)
09:16:00.142 INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_0 locally
09:16:00.169 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 6). 1874 bytes result sent to driver
09:16:00.171 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 7, localhost, ANY, 25283 bytes)
09:16:00.171 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 6) in 37 ms on localhost (1/2)
09:16:00.173 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 7)
09:16:00.178 INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_1 locally
09:16:00.194 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 7). 1874 bytes result sent to driver
09:16:00.196 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 7) in 27 ms on localhost (2/2)
09:16:00.196 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
09:16:00.196 INFO  o.a.spark.scheduler.DAGScheduler - Stage 5 (mapToPair at DatastaxSparkTest.java:86) finished in 0.083 s
09:16:00.196 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:16:00.196 INFO  o.a.spark.scheduler.DAGScheduler - running: Set()
09:16:00.196 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 2)
09:16:00.196 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:16:00.198 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List()
09:16:00.198 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 2 (MappedValuesRDD[10] at mapValues at DatastaxSparkTest.java:98), which is now runnable
09:16:00.199 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3384) called with curMem=4946997, maxMem=1019782103
09:16:00.199 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.3 KB, free 967.8 MB)
09:16:00.203 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 2 (MappedValuesRDD[10] at mapValues at DatastaxSparkTest.java:98)
09:16:00.203 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 2 tasks
09:16:00.204 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 8, localhost, PROCESS_LOCAL, 3237 bytes)
09:16:00.204 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 8)
09:16:00.207 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:16:00.207 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 2 non-empty blocks out of 2 blocks
09:16:00.207 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:16:00.211 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:16:00.212 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 1 non-empty blocks out of 2 blocks
09:16:00.212 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 1 ms
09:16:00.224 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 8). 1921 bytes result sent to driver
09:16:00.224 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 9, localhost, PROCESS_LOCAL, 3237 bytes)
09:16:00.225 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 8) in 22 ms on localhost (1/2)
09:16:00.225 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 9)
09:16:00.227 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:16:00.227 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 2 non-empty blocks out of 2 blocks
09:16:00.227 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:16:00.230 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:16:00.230 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 1 non-empty blocks out of 2 blocks
09:16:00.230 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:16:00.235 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 9). 1872 bytes result sent to driver
09:16:00.237 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 9) in 13 ms on localhost (2/2)
09:16:00.237 INFO  o.a.spark.scheduler.DAGScheduler - Stage 2 (collect at DatastaxSparkTest.java:103) finished in 0.034 s
09:16:00.237 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
09:16:00.238 INFO  org.apache.spark.SparkContext - Job finished: collect at DatastaxSparkTest.java:103, took 0.139942342 s
09:16:00.239 INFO  b.hashmade.spark.DatastaxSparkTest - Average distance by origin
09:16:00.244 INFO  b.hashmade.spark.DatastaxSparkTest - Albuquerque : 569.0
09:16:00.247 INFO  b.hashmade.spark.DatastaxSparkTest - Raleigh/Durham : 880.5
09:16:00.251 INFO  b.hashmade.spark.DatastaxSparkTest - Columbus : 926.0
09:16:00.255 INFO  b.hashmade.spark.DatastaxSparkTest - Washington : 1322.2067039106146
09:16:00.261 INFO  b.hashmade.spark.DatastaxSparkTest - Seattle : 2428.8387096774195
09:16:00.267 INFO  b.hashmade.spark.DatastaxSparkTest - Salt Lake City : 989.0
09:16:00.269 INFO  b.hashmade.spark.DatastaxSparkTest - Newark : 1904.1311475409836
09:16:00.273 INFO  b.hashmade.spark.DatastaxSparkTest - El Paso : 551.0
09:16:00.277 INFO  b.hashmade.spark.DatastaxSparkTest - Ontario : 1188.0
09:16:00.280 INFO  b.hashmade.spark.DatastaxSparkTest - Hartford : 1471.0
09:16:00.283 INFO  b.hashmade.spark.DatastaxSparkTest - San Antonio : 247.0
09:16:00.285 INFO  b.hashmade.spark.DatastaxSparkTest - Omaha : 583.0
09:16:00.288 INFO  b.hashmade.spark.DatastaxSparkTest - Portland : 1616.0
09:16:00.290 INFO  b.hashmade.spark.DatastaxSparkTest - Las Vegas : 1605.6666666666667
09:16:00.295 INFO  b.hashmade.spark.DatastaxSparkTest - Austin : 520.7835051546392
09:16:00.300 INFO  b.hashmade.spark.DatastaxSparkTest - Charlotte : 936.0
09:16:00.302 INFO  b.hashmade.spark.DatastaxSparkTest - Houston : 619.5172413793103
09:16:00.308 INFO  b.hashmade.spark.DatastaxSparkTest - Kansas City : 441.0
09:16:00.311 INFO  b.hashmade.spark.DatastaxSparkTest - Chicago : 906.5361010830325
09:16:00.316 INFO  b.hashmade.spark.DatastaxSparkTest - Palm Springs : 1126.0
09:16:00.319 INFO  b.hashmade.spark.DatastaxSparkTest - Honolulu : 3112.8231707317073
09:16:00.324 INFO  b.hashmade.spark.DatastaxSparkTest - Fort Lauderdale : 1182.0
09:16:00.330 INFO  b.hashmade.spark.DatastaxSparkTest - San Juan : 1045.0
09:16:00.332 INFO  b.hashmade.spark.DatastaxSparkTest - Louisville : 733.0
09:16:00.335 INFO  b.hashmade.spark.DatastaxSparkTest - San Francisco : 2099.5552486187844
09:16:00.339 INFO  b.hashmade.spark.DatastaxSparkTest - San Diego : 1558.4528301886792
09:16:00.344 INFO  b.hashmade.spark.DatastaxSparkTest - Mission/McAllen/Edinburg : 469.0
09:16:00.350 INFO  b.hashmade.spark.DatastaxSparkTest - West Palm Beach/Palm Beach : 1123.0
09:16:00.355 INFO  b.hashmade.spark.DatastaxSparkTest - Fayetteville : 280.0
09:16:00.358 INFO  b.hashmade.spark.DatastaxSparkTest - Wichita : 328.0
09:16:00.361 INFO  b.hashmade.spark.DatastaxSparkTest - Memphis : 432.0
09:16:00.364 INFO  b.hashmade.spark.DatastaxSparkTest - Kahului : 2881.043010752688
09:16:00.370 INFO  b.hashmade.spark.DatastaxSparkTest - St. Louis : 752.1764705882352
09:16:00.376 INFO  b.hashmade.spark.DatastaxSparkTest - Orlando : 1313.7662337662337
09:16:00.381 INFO  b.hashmade.spark.DatastaxSparkTest - Oklahoma City : 175.0
09:16:00.383 INFO  b.hashmade.spark.DatastaxSparkTest - Phoenix : 1154.0
09:16:00.386 INFO  b.hashmade.spark.DatastaxSparkTest - Santa Ana : 1315.5151515151515
09:16:00.391 INFO  b.hashmade.spark.DatastaxSparkTest - Baltimore : 1217.0
09:16:00.394 INFO  b.hashmade.spark.DatastaxSparkTest - Burbank : 1231.0
09:16:00.396 INFO  b.hashmade.spark.DatastaxSparkTest - Miami : 1404.1875808538164
09:16:00.401 INFO  b.hashmade.spark.DatastaxSparkTest - Kona : 2504.0
09:16:00.403 INFO  b.hashmade.spark.DatastaxSparkTest - New York : 1639.402862985685
09:16:00.409 INFO  b.hashmade.spark.DatastaxSparkTest - Norfolk : 1212.0
09:16:00.412 INFO  b.hashmade.spark.DatastaxSparkTest - San Jose : 1643.7894736842106
09:16:00.416 INFO  b.hashmade.spark.DatastaxSparkTest - Philadelphia : 1303.0
09:16:00.419 INFO  b.hashmade.spark.DatastaxSparkTest - Minneapolis : 852.0
09:16:00.422 INFO  b.hashmade.spark.DatastaxSparkTest - Lihue : 2615.0
09:16:00.425 INFO  b.hashmade.spark.DatastaxSparkTest - Tampa : 789.25
09:16:00.428 INFO  b.hashmade.spark.DatastaxSparkTest - Fort Myers : 1120.0
09:16:00.431 INFO  b.hashmade.spark.DatastaxSparkTest - Dayton : 861.0
09:16:00.433 INFO  b.hashmade.spark.DatastaxSparkTest - Colorado Springs : 592.0
09:16:00.439 INFO  b.hashmade.spark.DatastaxSparkTest - Boston : 1871.1462264150944
09:16:00.447 INFO  b.hashmade.spark.DatastaxSparkTest - Tulsa : 448.61290322580646
09:16:00.451 INFO  b.hashmade.spark.DatastaxSparkTest - Los Angeles : 2424.0010449320794
09:16:00.457 INFO  b.hashmade.spark.DatastaxSparkTest - Atlanta : 731.0
09:16:00.460 INFO  b.hashmade.spark.DatastaxSparkTest - Indianapolis : 761.0
09:16:00.463 INFO  b.hashmade.spark.DatastaxSparkTest - Charlotte Amalie : 1623.0
09:16:00.470 INFO  b.hashmade.spark.DatastaxSparkTest - Dallas/Fort Worth : 1040.072087912088
09:26:46.951 INFO  o.a.cassandra.thrift.ThriftServer - Stop listening to thrift clients
09:26:47.012 INFO  o.apache.cassandra.transport.Server - Stop listening for CQL clients
09:26:47.016 INFO  org.apache.cassandra.gms.Gossiper - Announcing shutdown
09:26:49.019 INFO  o.a.cassandra.net.MessagingService - Waiting for messaging service to quiesce
09:27:18.885 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:27:19.000 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:27:19.279 INFO  o.a.c.config.DatabaseDescriptor - DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
09:27:19.303 INFO  o.a.c.config.DatabaseDescriptor - Global memtable on-heap threshold is enabled at 450MB
09:27:19.308 INFO  o.a.c.config.DatabaseDescriptor - Global memtable off-heap threshold is enabled at 450MB
09:27:19.518 WARN  o.a.c.config.DatabaseDescriptor - Please rename encryption_options as server_encryption_options in the yaml
09:27:19.799 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:27:19.815 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:27:19.898 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:27:19.911 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:27:23.177 INFO  o.a.c.config.DatabaseDescriptor - Couldn't detect any schema definitions in local storage.
09:27:23.186 INFO  o.a.c.config.DatabaseDescriptor - To create keyspaces and column families, see 'help create' in cqlsh.
09:27:23.569 INFO  o.a.c.io.sstable.IndexSummaryManager - Initializing index summary manager with a memory pool size of 15 MB and a resize interval of 60 minutes
09:27:23.610 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:27:23.624 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:27:23.749 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:27:23.765 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:27:23.940 INFO  o.a.cassandra.net.MessagingService - Starting Messaging Service on port 7010
09:27:23.992 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:27:24.006 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:27:24.086 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:27:24.099 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:27:24.181 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:27:24.196 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:27:25.104 INFO  o.apache.cassandra.transport.Server - Using Netty Version: [netty-buffer=netty-buffer-4.0.23.Final.208198c, netty-codec=netty-codec-4.0.23.Final.208198c, netty-codec-http=netty-codec-http-4.0.23.Final.208198c, netty-codec-socks=netty-codec-socks-4.0.23.Final.208198c, netty-common=netty-common-4.0.23.Final.208198c, netty-handler=netty-handler-4.0.23.Final.208198c, netty-transport=netty-transport-4.0.23.Final.208198c, netty-transport-rxtx=netty-transport-rxtx-4.0.23.Final.208198c, netty-transport-sctp=netty-transport-sctp-4.0.23.Final.208198c, netty-transport-udt=netty-transport-udt-4.0.23.Final.208198c]
09:27:25.128 INFO  o.apache.cassandra.transport.Server - Starting listening for CQL clients on localhost/127.0.0.1:9142...
09:27:25.381 INFO  o.a.cassandra.thrift.ThriftServer - Binding thrift service to localhost/127.0.0.1:9171
09:27:25.397 INFO  o.a.cassandra.thrift.ThriftServer - Listening for thrift clients...
09:27:38.511 ERROR b.hashmade.spark.util.RoadTripUtil - Keyspace roadtrips already exists
com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.exceptions.AlreadyExistsException.copy(AlreadyExistsException.java:85) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.extractCauseFromExecutionException(DefaultResultSetFuture.java:259) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:175) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:52) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:36) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.cassandraunit.CQLDataLoader.load(CQLDataLoader.java:36) ~[cassandra-unit-2.0.2.2.jar:na]
	at blog.hashmade.spark.util.RoadTripUtil.initCassandraWithRoadTrips(RoadTripUtil.java:46) ~[classes/:na]
	at blog.hashmade.spark.DatastaxSparkTest.main(DatastaxSparkTest.java:30) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_25]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_25]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_25]
	at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_25]
	at org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:297) [exec-maven-plugin-1.2.1.jar:na]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_25]
Caused by: com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.exceptions.AlreadyExistsException.copy(AlreadyExistsException.java:85) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:105) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.onSet(DefaultResultSetFuture.java:110) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.RequestHandler.setFinalResult(RequestHandler.java:246) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.RequestHandler.onSet(RequestHandler.java:418) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Connection$Dispatcher.messageReceived(Connection.java:661) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:318) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) ~[netty-3.9.0.Final.jar:na]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_25]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_25]
	... 1 common frames omitted
Caused by: com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:70) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:38) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:168) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:66) ~[netty-3.9.0.Final.jar:na]
	... 21 common frames omitted
09:27:39.085 INFO  org.apache.spark.SecurityManager - Changing view acls to: mdoctor,
09:27:39.092 INFO  org.apache.spark.SecurityManager - Changing modify acls to: mdoctor,
09:27:39.098 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(mdoctor, ); users with modify permissions: Set(mdoctor, )
09:27:39.506 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
09:27:39.558 INFO  Remoting - Starting remoting
09:27:39.692 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54459]
09:27:39.701 INFO  Remoting - Remoting now listens on addresses: [akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54459]
09:27:39.718 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54459.
09:27:39.746 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
09:27:39.761 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
09:27:39.791 INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\mdoctor\AppData\Local\Temp\spark-local-20150105092739-a4dd
09:27:39.824 INFO  org.apache.spark.util.Utils - Successfully started service 'Connection manager for block manager' on port 54462.
09:27:39.832 INFO  o.a.spark.network.ConnectionManager - Bound socket to port 54462 with id = ConnectionManagerId(MDOCTOR.chi.chicorp,54462)
09:27:39.842 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 972.5 MB
09:27:39.848 INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
09:27:39.850 INFO  o.a.s.s.BlockManagerMasterActor - Registering block manager MDOCTOR.chi.chicorp:54462 with 972.5 MB RAM
09:27:39.853 INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
09:27:39.871 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\mdoctor\AppData\Local\Temp\spark-0aa84125-9f17-4a41-ade4-bd4e95693ce9
09:27:39.887 INFO  org.apache.spark.HttpServer - Starting HTTP Server
09:27:39.963 INFO  org.eclipse.jetty.server.Server - jetty-8.1.14.v20131031
09:27:39.983 INFO  o.e.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:54463
09:27:39.988 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 54463.
09:27:40.606 INFO  org.eclipse.jetty.server.Server - jetty-8.1.14.v20131031
09:27:40.621 INFO  o.e.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
09:27:40.627 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
09:27:40.637 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://MDOCTOR.chi.chicorp:4040
09:27:40.910 INFO  org.apache.spark.util.AkkaUtils - Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54459/user/HeartbeatReceiver
09:27:41.404 INFO  c.d.s.c.cql.CassandraConnector - Connected to Cassandra cluster: CassClusterDev001
09:27:41.410 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:27:41.413 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:27:41.413 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:27:41.427 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:27:41.431 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:27:41.454 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:27:41.454 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:27:41.466 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:27:41.467 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:27:41.479 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:27:42.006 INFO  c.d.s.c.cql.CassandraConnector - Disconnected from Cassandra cluster: CassClusterDev001
09:27:42.070 INFO  org.apache.spark.SparkContext - Starting job: collect at DatastaxSparkTest.java:80
09:27:42.088 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 1 (groupBy at DatastaxSparkTest.java:66)
09:27:42.090 INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (collect at DatastaxSparkTest.java:80) with 2 output partitions (allowLocal=false)
09:27:42.090 INFO  o.a.spark.scheduler.DAGScheduler - Final stage: Stage 0(collect at DatastaxSparkTest.java:80)
09:27:42.091 INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 1)
09:27:42.094 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(Stage 1)
09:27:42.099 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 1 (MappedRDD[1] at groupBy at DatastaxSparkTest.java:66), which has no missing parents
09:27:42.153 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(6456) called with curMem=0, maxMem=1019782103
09:27:42.155 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 6.3 KB, free 972.5 MB)
09:27:42.187 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 1 (MappedRDD[1] at groupBy at DatastaxSparkTest.java:66)
09:27:42.189 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 2 tasks
09:27:42.220 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 0, localhost, ANY, 25221 bytes)
09:27:42.230 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 0)
09:27:42.273 INFO  org.apache.spark.CacheManager - Partition rdd_0_0 not found, computing it
09:27:42.440 INFO  c.d.s.c.cql.CassandraConnector - Connected to Cassandra cluster: CassClusterDev001
09:27:42.440 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:27:42.445 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:27:42.445 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:27:42.451 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:27:42.463 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:27:42.489 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:27:42.489 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:27:42.499 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:27:42.500 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:27:42.511 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:27:44.823 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=6456, maxMem=1019782103
09:27:44.824 INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_0 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:27:44.825 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_0 in memory on MDOCTOR.chi.chicorp:54462 (size: 16.0 B, free: 972.5 MB)
09:27:44.825 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_0_0
09:27:44.835 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 0). 1385 bytes result sent to driver
09:27:44.837 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 1, localhost, ANY, 25283 bytes)
09:27:44.838 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 1)
09:27:44.845 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 0) in 2635 ms on localhost (1/2)
09:27:44.852 INFO  org.apache.spark.CacheManager - Partition rdd_0_1 not found, computing it
09:27:46.292 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=6472, maxMem=1019782103
09:27:46.295 INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_1 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:27:46.300 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_1 in memory on MDOCTOR.chi.chicorp:54462 (size: 16.0 B, free: 972.5 MB)
09:27:46.306 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_0_1
09:27:46.307 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 1). 1385 bytes result sent to driver
09:27:46.310 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 1) in 1473 ms on localhost (2/2)
09:27:46.310 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
09:27:46.311 INFO  o.a.spark.scheduler.DAGScheduler - Stage 1 (groupBy at DatastaxSparkTest.java:66) finished in 4.113 s
09:27:46.312 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:27:46.312 INFO  o.a.spark.scheduler.DAGScheduler - running: Set()
09:27:46.313 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 0)
09:27:46.313 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:27:46.319 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 0: List()
09:27:46.321 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 0 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72), which is now runnable
09:27:46.323 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2864) called with curMem=6488, maxMem=1019782103
09:27:46.323 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 2.8 KB, free 972.5 MB)
09:27:46.326 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 0 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72)
09:27:46.326 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 2 tasks
09:27:46.327 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 948 bytes)
09:27:46.328 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 2)
09:27:46.330 INFO  org.apache.spark.CacheManager - Partition rdd_4_0 not found, computing it
09:27:46.338 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:27:46.341 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:27:46.342 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 4 ms
09:27:46.359 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=9352, maxMem=1019782103
09:27:46.359 INFO  org.apache.spark.storage.MemoryStore - Block rdd_4_0 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:27:46.360 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_4_0 in memory on MDOCTOR.chi.chicorp:54462 (size: 16.0 B, free: 972.5 MB)
09:27:46.360 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_4_0
09:27:46.362 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 2). 1391 bytes result sent to driver
09:27:46.369 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 948 bytes)
09:27:46.370 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 3)
09:27:46.372 INFO  org.apache.spark.CacheManager - Partition rdd_4_1 not found, computing it
09:27:46.372 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:27:46.372 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:27:46.372 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:27:46.373 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(16) called with curMem=9368, maxMem=1019782103
09:27:46.373 INFO  org.apache.spark.storage.MemoryStore - Block rdd_4_1 stored as values in memory (estimated size 16.0 B, free 972.5 MB)
09:27:46.373 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_4_1 in memory on MDOCTOR.chi.chicorp:54462 (size: 16.0 B, free: 972.5 MB)
09:27:46.374 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_4_1
09:27:46.374 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 3). 1391 bytes result sent to driver
09:27:46.382 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 2) in 55 ms on localhost (1/2)
09:27:46.391 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 3) in 28 ms on localhost (2/2)
09:27:46.391 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
09:27:46.391 INFO  o.a.spark.scheduler.DAGScheduler - Stage 0 (collect at DatastaxSparkTest.java:80) finished in 0.064 s
09:27:46.397 INFO  org.apache.spark.SparkContext - Job finished: collect at DatastaxSparkTest.java:80, took 4.325956623 s
09:27:46.399 INFO  b.hashmade.spark.DatastaxSparkTest - Nb RoadTrips by origin
09:27:46.429 INFO  org.apache.spark.SparkContext - Starting job: collect at DatastaxSparkTest.java:103
09:27:46.433 INFO  o.a.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 148 bytes
09:27:46.436 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 4 (mapToPair at DatastaxSparkTest.java:72)
09:27:46.436 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 5 (mapToPair at DatastaxSparkTest.java:86)
09:27:46.436 INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at DatastaxSparkTest.java:103) with 2 output partitions (allowLocal=false)
09:27:46.436 INFO  o.a.spark.scheduler.DAGScheduler - Final stage: Stage 2(collect at DatastaxSparkTest.java:103)
09:27:46.436 INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 5, Stage 4)
09:27:46.437 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(Stage 5, Stage 4)
09:27:46.438 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 4 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72), which has no missing parents
09:27:46.440 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2768) called with curMem=9384, maxMem=1019782103
09:27:46.440 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.7 KB, free 972.5 MB)
09:27:46.440 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 4 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72)
09:27:46.441 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 2 tasks
09:27:46.443 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4, localhost, ANY, 937 bytes)
09:27:46.443 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
09:27:46.445 INFO  o.apache.spark.storage.BlockManager - Found block rdd_4_0 locally
09:27:46.451 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 5 (MappedRDD[5] at mapToPair at DatastaxSparkTest.java:86), which has no missing parents
09:27:46.452 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(6464) called with curMem=12152, maxMem=1019782103
09:27:46.452 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 6.3 KB, free 972.5 MB)
09:27:46.455 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 5 (MappedRDD[5] at mapToPair at DatastaxSparkTest.java:86)
09:27:46.455 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 2 tasks
09:27:46.460 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1874 bytes result sent to driver
09:27:46.461 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 4.0 (TID 5, localhost, ANY, 937 bytes)
09:27:46.462 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 4.0 (TID 5)
09:27:46.463 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 20 ms on localhost (1/2)
09:27:46.465 INFO  o.apache.spark.storage.BlockManager - Found block rdd_4_1 locally
09:27:46.466 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 4.0 (TID 5). 1874 bytes result sent to driver
09:27:46.469 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 6, localhost, ANY, 25221 bytes)
09:27:46.470 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 6)
09:27:46.474 INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_0 locally
09:27:46.475 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 6). 1874 bytes result sent to driver
09:27:46.479 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 7, localhost, ANY, 25283 bytes)
09:27:46.480 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 7)
09:27:46.486 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 6) in 19 ms on localhost (1/2)
09:27:46.486 INFO  o.a.spark.scheduler.DAGScheduler - Stage 4 (mapToPair at DatastaxSparkTest.java:72) finished in 0.044 s
09:27:46.487 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:27:46.487 INFO  o.a.spark.scheduler.DAGScheduler - running: Set(Stage 5)
09:27:46.487 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 2)
09:27:46.487 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:27:46.487 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 4.0 (TID 5) in 25 ms on localhost (2/2)
09:27:46.487 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
09:27:46.489 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List(Stage 5)
09:27:46.490 INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_1 locally
09:27:46.491 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 7). 1874 bytes result sent to driver
09:27:46.492 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 7) in 16 ms on localhost (2/2)
09:27:46.493 INFO  o.a.spark.scheduler.DAGScheduler - Stage 5 (mapToPair at DatastaxSparkTest.java:86) finished in 0.036 s
09:27:46.493 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
09:27:46.493 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:27:46.493 INFO  o.a.spark.scheduler.DAGScheduler - running: Set()
09:27:46.493 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 2)
09:27:46.493 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:27:46.495 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List()
09:27:46.495 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 2 (MappedValuesRDD[10] at mapValues at DatastaxSparkTest.java:98), which is now runnable
09:27:46.496 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3384) called with curMem=18616, maxMem=1019782103
09:27:46.496 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.3 KB, free 972.5 MB)
09:27:46.501 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 2 (MappedValuesRDD[10] at mapValues at DatastaxSparkTest.java:98)
09:27:46.501 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 2 tasks
09:27:46.502 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 8, localhost, PROCESS_LOCAL, 3237 bytes)
09:27:46.502 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 8)
09:27:46.506 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:27:46.506 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:27:46.506 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:27:46.508 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:27:46.508 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:27:46.508 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:27:46.513 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 8). 822 bytes result sent to driver
09:27:46.514 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 9, localhost, PROCESS_LOCAL, 3237 bytes)
09:27:46.514 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 9)
09:27:46.514 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 8) in 12 ms on localhost (1/2)
09:27:46.516 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:27:46.516 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:27:46.517 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 1 ms
09:27:46.517 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:27:46.517 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:27:46.517 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:27:46.518 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 9). 822 bytes result sent to driver
09:27:46.518 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 9) in 5 ms on localhost (2/2)
09:27:46.519 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
09:27:46.519 INFO  o.a.spark.scheduler.DAGScheduler - Stage 2 (collect at DatastaxSparkTest.java:103) finished in 0.018 s
09:27:46.519 INFO  org.apache.spark.SparkContext - Job finished: collect at DatastaxSparkTest.java:103, took 0.090163423 s
09:27:46.520 INFO  b.hashmade.spark.DatastaxSparkTest - Average distance by origin
09:27:46.741 INFO  c.d.s.c.cql.CassandraConnector - Disconnected from Cassandra cluster: CassClusterDev001
09:41:27.512 INFO  o.a.cassandra.thrift.ThriftServer - Stop listening to thrift clients
09:41:27.547 INFO  o.apache.cassandra.transport.Server - Stop listening for CQL clients
09:41:27.558 INFO  org.apache.cassandra.gms.Gossiper - Announcing shutdown
09:41:29.560 INFO  o.a.cassandra.net.MessagingService - Waiting for messaging service to quiesce
09:41:29.568 INFO  o.a.cassandra.net.MessagingService - MessagingService has terminated the accept() thread
09:41:46.830 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:41:47.034 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:41:47.359 INFO  o.a.c.config.DatabaseDescriptor - DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
09:41:47.388 INFO  o.a.c.config.DatabaseDescriptor - Global memtable on-heap threshold is enabled at 450MB
09:41:47.393 INFO  o.a.c.config.DatabaseDescriptor - Global memtable off-heap threshold is enabled at 450MB
09:41:47.725 WARN  o.a.c.config.DatabaseDescriptor - Please rename encryption_options as server_encryption_options in the yaml
09:41:48.126 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:41:48.146 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:41:48.264 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:41:48.282 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:41:50.657 INFO  o.a.c.config.DatabaseDescriptor - Couldn't detect any schema definitions in local storage.
09:41:50.669 INFO  o.a.c.config.DatabaseDescriptor - To create keyspaces and column families, see 'help create' in cqlsh.
09:41:51.045 INFO  o.a.c.io.sstable.IndexSummaryManager - Initializing index summary manager with a memory pool size of 13 MB and a resize interval of 60 minutes
09:41:51.090 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:41:51.108 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:41:51.237 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:41:51.252 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:41:51.359 INFO  o.a.cassandra.net.MessagingService - Starting Messaging Service on port 7010
09:41:51.382 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:41:51.394 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:41:51.480 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:41:51.494 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:41:51.577 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:41:51.589 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:41:52.307 INFO  o.apache.cassandra.transport.Server - Using Netty Version: [netty-buffer=netty-buffer-4.0.23.Final.208198c, netty-codec=netty-codec-4.0.23.Final.208198c, netty-codec-http=netty-codec-http-4.0.23.Final.208198c, netty-codec-socks=netty-codec-socks-4.0.23.Final.208198c, netty-common=netty-common-4.0.23.Final.208198c, netty-handler=netty-handler-4.0.23.Final.208198c, netty-transport=netty-transport-4.0.23.Final.208198c, netty-transport-rxtx=netty-transport-rxtx-4.0.23.Final.208198c, netty-transport-sctp=netty-transport-sctp-4.0.23.Final.208198c, netty-transport-udt=netty-transport-udt-4.0.23.Final.208198c]
09:41:52.330 INFO  o.apache.cassandra.transport.Server - Starting listening for CQL clients on localhost/127.0.0.1:9142...
09:41:52.653 INFO  o.a.cassandra.thrift.ThriftServer - Binding thrift service to localhost/127.0.0.1:9171
09:41:52.667 INFO  o.a.cassandra.thrift.ThriftServer - Listening for thrift clients...
09:42:10.224 INFO  org.apache.spark.SecurityManager - Changing view acls to: mdoctor,
09:42:10.230 INFO  org.apache.spark.SecurityManager - Changing modify acls to: mdoctor,
09:42:10.235 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(mdoctor, ); users with modify permissions: Set(mdoctor, )
09:42:10.643 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
09:42:10.702 INFO  Remoting - Starting remoting
09:42:10.823 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54645]
09:42:10.839 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54645.
09:42:10.843 INFO  Remoting - Remoting now listens on addresses: [akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54645]
09:42:10.881 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
09:42:10.893 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
09:42:10.923 INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\mdoctor\AppData\Local\Temp\spark-local-20150105094210-97aa
09:42:10.956 INFO  org.apache.spark.util.Utils - Successfully started service 'Connection manager for block manager' on port 54648.
09:42:10.964 INFO  o.a.spark.network.ConnectionManager - Bound socket to port 54648 with id = ConnectionManagerId(MDOCTOR.chi.chicorp,54648)
09:42:10.976 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 972.5 MB
09:42:10.982 INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
09:42:10.983 INFO  o.a.s.s.BlockManagerMasterActor - Registering block manager MDOCTOR.chi.chicorp:54648 with 972.5 MB RAM
09:42:10.985 INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
09:42:11.003 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\mdoctor\AppData\Local\Temp\spark-93cfb395-21df-45fd-ba7e-3331ba52aa4a
09:42:11.018 INFO  org.apache.spark.HttpServer - Starting HTTP Server
09:42:11.082 INFO  org.eclipse.jetty.server.Server - jetty-8.1.14.v20131031
09:42:11.358 INFO  o.e.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:54649
09:42:11.363 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 54649.
09:42:11.560 INFO  org.eclipse.jetty.server.Server - jetty-8.1.14.v20131031
09:42:11.572 INFO  o.e.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
09:42:11.577 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
09:42:11.585 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://MDOCTOR.chi.chicorp:4040
09:42:11.801 INFO  org.apache.spark.util.AkkaUtils - Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54645/user/HeartbeatReceiver
09:42:12.176 INFO  c.d.s.c.cql.CassandraConnector - Connected to Cassandra cluster: CassClusterDev001
09:42:12.181 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:42:12.182 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:42:12.183 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:42:12.194 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:42:12.197 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:42:12.227 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:42:12.227 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:42:12.228 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:42:12.232 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:42:12.247 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:42:12.643 INFO  c.d.s.c.cql.CassandraConnector - Disconnected from Cassandra cluster: CassClusterDev001
09:42:12.767 INFO  org.apache.spark.SparkContext - Starting job: collect at DatastaxSparkTest.java:80
09:42:12.782 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 1 (groupBy at DatastaxSparkTest.java:66)
09:42:12.784 INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (collect at DatastaxSparkTest.java:80) with 2 output partitions (allowLocal=false)
09:42:12.784 INFO  o.a.spark.scheduler.DAGScheduler - Final stage: Stage 0(collect at DatastaxSparkTest.java:80)
09:42:12.785 INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 1)
09:42:12.789 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(Stage 1)
09:42:12.795 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 1 (MappedRDD[1] at groupBy at DatastaxSparkTest.java:66), which has no missing parents
09:42:12.854 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(6456) called with curMem=0, maxMem=1019782103
09:42:12.856 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 6.3 KB, free 972.5 MB)
09:42:12.883 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 1 (MappedRDD[1] at groupBy at DatastaxSparkTest.java:66)
09:42:12.884 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 2 tasks
09:42:12.912 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 0, localhost, ANY, 25221 bytes)
09:42:12.918 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 0)
09:42:12.950 INFO  org.apache.spark.CacheManager - Partition rdd_0_0 not found, computing it
09:42:13.119 INFO  c.d.s.c.cql.CassandraConnector - Connected to Cassandra cluster: CassClusterDev001
09:42:13.119 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:42:13.125 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:42:13.128 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:42:13.130 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:42:13.134 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:42:13.148 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:42:13.157 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:42:13.170 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:42:13.177 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:42:13.182 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:42:15.526 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2372497) called with curMem=6456, maxMem=1019782103
09:42:15.526 INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_0 stored as values in memory (estimated size 2.3 MB, free 970.3 MB)
09:42:15.529 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_0 in memory on MDOCTOR.chi.chicorp:54648 (size: 2.3 MB, free: 970.3 MB)
09:42:15.530 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_0_0
09:42:15.678 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 0). 1385 bytes result sent to driver
09:42:15.680 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 1, localhost, ANY, 25283 bytes)
09:42:15.681 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 1)
09:42:15.683 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 0) in 2782 ms on localhost (1/2)
09:42:15.691 INFO  org.apache.spark.CacheManager - Partition rdd_0_1 not found, computing it
09:42:17.481 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2549804) called with curMem=2378953, maxMem=1019782103
09:42:17.481 INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_1 stored as values in memory (estimated size 2.4 MB, free 967.8 MB)
09:42:17.481 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_1 in memory on MDOCTOR.chi.chicorp:54648 (size: 2.4 MB, free: 967.8 MB)
09:42:17.482 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_0_1
09:42:17.540 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 1). 1385 bytes result sent to driver
09:42:17.545 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 1) in 1867 ms on localhost (2/2)
09:42:17.546 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
09:42:17.547 INFO  o.a.spark.scheduler.DAGScheduler - Stage 1 (groupBy at DatastaxSparkTest.java:66) finished in 4.655 s
09:42:17.548 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:42:17.548 INFO  o.a.spark.scheduler.DAGScheduler - running: Set()
09:42:17.548 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 0)
09:42:17.549 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:42:17.554 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 0: List()
09:42:17.556 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 0 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72), which is now runnable
09:42:17.557 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2864) called with curMem=4928757, maxMem=1019782103
09:42:17.557 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 2.8 KB, free 967.8 MB)
09:42:17.559 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 0 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72)
09:42:17.559 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 2 tasks
09:42:17.560 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 948 bytes)
09:42:17.560 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 2)
09:42:17.563 INFO  org.apache.spark.CacheManager - Partition rdd_4_0 not found, computing it
09:42:17.569 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:42:17.571 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 2 non-empty blocks out of 2 blocks
09:42:17.572 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 3 ms
09:42:17.799 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3080) called with curMem=4931621, maxMem=1019782103
09:42:17.799 INFO  org.apache.spark.storage.MemoryStore - Block rdd_4_0 stored as values in memory (estimated size 3.0 KB, free 967.8 MB)
09:42:17.800 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_4_0 in memory on MDOCTOR.chi.chicorp:54648 (size: 3.0 KB, free: 967.8 MB)
09:42:17.800 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_4_0
09:42:17.801 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 2). 2313 bytes result sent to driver
09:42:17.802 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 948 bytes)
09:42:17.803 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 3)
09:42:17.804 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 2) in 243 ms on localhost (1/2)
09:42:17.804 INFO  org.apache.spark.CacheManager - Partition rdd_4_1 not found, computing it
09:42:17.804 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:42:17.804 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 2 non-empty blocks out of 2 blocks
09:42:17.804 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:42:17.875 INFO  c.d.s.c.cql.CassandraConnector - Disconnected from Cassandra cluster: CassClusterDev001
09:42:18.009 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3064) called with curMem=4934701, maxMem=1019782103
09:42:18.009 INFO  org.apache.spark.storage.MemoryStore - Block rdd_4_1 stored as values in memory (estimated size 3.0 KB, free 967.8 MB)
09:42:18.010 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_4_1 in memory on MDOCTOR.chi.chicorp:54648 (size: 3.0 KB, free: 967.8 MB)
09:42:18.010 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_4_1
09:42:18.010 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 3). 2279 bytes result sent to driver
09:42:18.011 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 3) in 209 ms on localhost (2/2)
09:42:18.011 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
09:42:18.012 INFO  o.a.spark.scheduler.DAGScheduler - Stage 0 (collect at DatastaxSparkTest.java:80) finished in 0.451 s
09:42:18.019 INFO  org.apache.spark.SparkContext - Job finished: collect at DatastaxSparkTest.java:80, took 5.2509716 s
09:42:18.021 INFO  b.hashmade.spark.DatastaxSparkTest - Nb RoadTrips by origin
09:42:18.023 INFO  b.hashmade.spark.DatastaxSparkTest - Albuquerque : 61
09:42:18.027 INFO  b.hashmade.spark.DatastaxSparkTest - Raleigh/Durham : 62
09:42:18.031 INFO  b.hashmade.spark.DatastaxSparkTest - Columbus : 31
09:42:18.034 INFO  b.hashmade.spark.DatastaxSparkTest - Washington : 358
09:42:18.038 INFO  b.hashmade.spark.DatastaxSparkTest - Seattle : 31
09:42:18.041 INFO  b.hashmade.spark.DatastaxSparkTest - Salt Lake City : 31
09:42:18.044 INFO  b.hashmade.spark.DatastaxSparkTest - Newark : 61
09:42:18.048 INFO  b.hashmade.spark.DatastaxSparkTest - El Paso : 31
09:42:18.051 INFO  b.hashmade.spark.DatastaxSparkTest - Ontario : 36
09:42:18.055 INFO  b.hashmade.spark.DatastaxSparkTest - Hartford : 31
09:42:18.058 INFO  b.hashmade.spark.DatastaxSparkTest - San Antonio : 176
09:42:18.061 INFO  b.hashmade.spark.DatastaxSparkTest - Omaha : 57
09:42:18.064 INFO  b.hashmade.spark.DatastaxSparkTest - Las Vegas : 93
09:42:18.067 INFO  b.hashmade.spark.DatastaxSparkTest - Portland : 9
09:42:18.071 INFO  b.hashmade.spark.DatastaxSparkTest - Austin : 194
09:42:18.074 INFO  b.hashmade.spark.DatastaxSparkTest - Charlotte : 31
09:42:18.078 INFO  b.hashmade.spark.DatastaxSparkTest - Houston : 58
09:42:18.082 INFO  b.hashmade.spark.DatastaxSparkTest - Kansas City : 93
09:42:18.085 INFO  b.hashmade.spark.DatastaxSparkTest - Chicago : 1108
09:42:18.088 INFO  b.hashmade.spark.DatastaxSparkTest - Palm Springs : 31
09:42:18.092 INFO  b.hashmade.spark.DatastaxSparkTest - Honolulu : 164
09:42:18.095 INFO  b.hashmade.spark.DatastaxSparkTest - San Juan : 62
09:42:18.098 INFO  b.hashmade.spark.DatastaxSparkTest - Fort Lauderdale : 31
09:42:18.101 INFO  b.hashmade.spark.DatastaxSparkTest - Louisville : 1
09:42:18.104 INFO  b.hashmade.spark.DatastaxSparkTest - San Francisco : 362
09:42:18.108 INFO  b.hashmade.spark.DatastaxSparkTest - San Diego : 159
09:42:18.111 INFO  b.hashmade.spark.DatastaxSparkTest - Mission/McAllen/Edinburg : 30
09:42:18.116 INFO  b.hashmade.spark.DatastaxSparkTest - West Palm Beach/Palm Beach : 62
09:42:18.121 INFO  b.hashmade.spark.DatastaxSparkTest - Fayetteville : 31
09:42:18.124 INFO  b.hashmade.spark.DatastaxSparkTest - Wichita : 62
09:42:18.127 INFO  b.hashmade.spark.DatastaxSparkTest - Memphis : 24
09:42:18.130 INFO  b.hashmade.spark.DatastaxSparkTest - Kahului : 93
09:42:18.132 INFO  b.hashmade.spark.DatastaxSparkTest - St. Louis : 204
09:42:18.135 INFO  b.hashmade.spark.DatastaxSparkTest - Orlando : 154
09:42:18.138 INFO  b.hashmade.spark.DatastaxSparkTest - Oklahoma City : 31
09:42:18.142 INFO  b.hashmade.spark.DatastaxSparkTest - Phoenix : 124
09:42:18.144 INFO  b.hashmade.spark.DatastaxSparkTest - Santa Ana : 33
09:42:18.147 INFO  b.hashmade.spark.DatastaxSparkTest - Baltimore : 27
09:42:18.150 INFO  b.hashmade.spark.DatastaxSparkTest - Burbank : 8
09:42:18.153 INFO  b.hashmade.spark.DatastaxSparkTest - Miami : 773
09:42:18.156 INFO  b.hashmade.spark.DatastaxSparkTest - Kona : 31
09:42:18.159 INFO  b.hashmade.spark.DatastaxSparkTest - New York : 978
09:42:18.161 INFO  b.hashmade.spark.DatastaxSparkTest - Norfolk : 50
09:42:18.164 INFO  b.hashmade.spark.DatastaxSparkTest - San Jose : 57
09:42:18.167 INFO  b.hashmade.spark.DatastaxSparkTest - Philadelphia : 8
09:42:18.170 INFO  b.hashmade.spark.DatastaxSparkTest - Minneapolis : 30
09:42:18.173 INFO  b.hashmade.spark.DatastaxSparkTest - Lihue : 42
09:42:18.176 INFO  b.hashmade.spark.DatastaxSparkTest - Tampa : 124
09:42:18.179 INFO  b.hashmade.spark.DatastaxSparkTest - Fort Myers : 31
09:42:18.181 INFO  b.hashmade.spark.DatastaxSparkTest - Dayton : 31
09:42:18.185 INFO  b.hashmade.spark.DatastaxSparkTest - Colorado Springs : 31
09:42:18.187 INFO  b.hashmade.spark.DatastaxSparkTest - Boston : 212
09:42:18.190 INFO  b.hashmade.spark.DatastaxSparkTest - Tulsa : 62
09:42:18.193 INFO  b.hashmade.spark.DatastaxSparkTest - Los Angeles : 957
09:42:18.196 INFO  b.hashmade.spark.DatastaxSparkTest - Atlanta : 31
09:42:18.198 INFO  b.hashmade.spark.DatastaxSparkTest - Indianapolis : 1
09:42:18.201 INFO  b.hashmade.spark.DatastaxSparkTest - Dallas/Fort Worth : 2275
09:42:18.206 INFO  b.hashmade.spark.DatastaxSparkTest - Charlotte Amalie : 31
09:42:18.241 INFO  org.apache.spark.SparkContext - Starting job: collect at DatastaxSparkTest.java:103
09:42:18.243 INFO  o.a.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 153 bytes
09:42:18.245 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 4 (mapToPair at DatastaxSparkTest.java:72)
09:42:18.246 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 5 (mapToPair at DatastaxSparkTest.java:86)
09:42:18.246 INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at DatastaxSparkTest.java:103) with 2 output partitions (allowLocal=false)
09:42:18.246 INFO  o.a.spark.scheduler.DAGScheduler - Final stage: Stage 2(collect at DatastaxSparkTest.java:103)
09:42:18.246 INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 5, Stage 4)
09:42:18.247 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(Stage 5, Stage 4)
09:42:18.248 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 4 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72), which has no missing parents
09:42:18.248 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2768) called with curMem=4937765, maxMem=1019782103
09:42:18.249 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.7 KB, free 967.8 MB)
09:42:18.249 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 4 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72)
09:42:18.249 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 2 tasks
09:42:18.250 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4, localhost, ANY, 937 bytes)
09:42:18.250 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
09:42:18.251 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 5 (MappedRDD[5] at mapToPair at DatastaxSparkTest.java:86), which has no missing parents
09:42:18.252 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(6464) called with curMem=4940533, maxMem=1019782103
09:42:18.252 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 6.3 KB, free 967.8 MB)
09:42:18.252 INFO  o.apache.spark.storage.BlockManager - Found block rdd_4_0 locally
09:42:18.257 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 5 (MappedRDD[5] at mapToPair at DatastaxSparkTest.java:86)
09:42:18.257 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 2 tasks
09:42:18.265 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1874 bytes result sent to driver
09:42:18.266 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 4.0 (TID 5, localhost, ANY, 937 bytes)
09:42:18.268 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 17 ms on localhost (1/2)
09:42:18.273 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 4.0 (TID 5)
09:42:18.276 INFO  o.apache.spark.storage.BlockManager - Found block rdd_4_1 locally
09:42:18.277 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 4.0 (TID 5). 1874 bytes result sent to driver
09:42:18.290 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 6, localhost, ANY, 25221 bytes)
09:42:18.291 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 6)
09:42:18.296 INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_0 locally
09:42:18.297 INFO  o.a.spark.scheduler.DAGScheduler - Stage 4 (mapToPair at DatastaxSparkTest.java:72) finished in 0.047 s
09:42:18.297 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:42:18.297 INFO  o.a.spark.scheduler.DAGScheduler - running: Set(Stage 5)
09:42:18.297 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 2)
09:42:18.297 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:42:18.302 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 4.0 (TID 5) in 28 ms on localhost (2/2)
09:42:18.317 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List(Stage 5)
09:42:18.319 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
09:42:18.319 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 6). 1874 bytes result sent to driver
09:42:18.321 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 7, localhost, ANY, 25283 bytes)
09:42:18.322 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 7)
09:42:18.323 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 6) in 34 ms on localhost (1/2)
09:42:18.329 INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_1 locally
09:42:18.343 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 7). 1874 bytes result sent to driver
09:42:18.345 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 7) in 25 ms on localhost (2/2)
09:42:18.345 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
09:42:18.345 INFO  o.a.spark.scheduler.DAGScheduler - Stage 5 (mapToPair at DatastaxSparkTest.java:86) finished in 0.087 s
09:42:18.345 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:42:18.345 INFO  o.a.spark.scheduler.DAGScheduler - running: Set()
09:42:18.345 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 2)
09:42:18.345 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:42:18.351 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List()
09:42:18.352 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 2 (MappedValuesRDD[10] at mapValues at DatastaxSparkTest.java:98), which is now runnable
09:42:18.352 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3384) called with curMem=4946997, maxMem=1019782103
09:42:18.353 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.3 KB, free 967.8 MB)
09:42:18.359 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 2 (MappedValuesRDD[10] at mapValues at DatastaxSparkTest.java:98)
09:42:18.360 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 2 tasks
09:42:18.361 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 8, localhost, PROCESS_LOCAL, 3237 bytes)
09:42:18.361 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 8)
09:42:18.364 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:42:18.364 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 2 non-empty blocks out of 2 blocks
09:42:18.364 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:42:18.367 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:42:18.367 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 1 non-empty blocks out of 2 blocks
09:42:18.367 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:42:18.374 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 8). 1921 bytes result sent to driver
09:42:18.374 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 9, localhost, PROCESS_LOCAL, 3237 bytes)
09:42:18.375 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 9)
09:42:18.375 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 8) in 14 ms on localhost (1/2)
09:42:18.376 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:42:18.377 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 2 non-empty blocks out of 2 blocks
09:42:18.377 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 1 ms
09:42:18.379 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:42:18.379 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 1 non-empty blocks out of 2 blocks
09:42:18.379 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:42:18.382 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 9). 1872 bytes result sent to driver
09:42:18.383 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 9) in 8 ms on localhost (2/2)
09:42:18.383 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
09:42:18.383 INFO  o.a.spark.scheduler.DAGScheduler - Stage 2 (collect at DatastaxSparkTest.java:103) finished in 0.022 s
09:42:18.383 INFO  org.apache.spark.SparkContext - Job finished: collect at DatastaxSparkTest.java:103, took 0.142351196 s
09:42:18.383 INFO  b.hashmade.spark.DatastaxSparkTest - Average distance by origin
09:42:18.388 INFO  b.hashmade.spark.DatastaxSparkTest - Albuquerque : 569.0
09:42:18.391 INFO  b.hashmade.spark.DatastaxSparkTest - Raleigh/Durham : 880.5
09:42:18.394 INFO  b.hashmade.spark.DatastaxSparkTest - Columbus : 926.0
09:42:18.398 INFO  b.hashmade.spark.DatastaxSparkTest - Washington : 1322.2067039106146
09:42:18.404 INFO  b.hashmade.spark.DatastaxSparkTest - Seattle : 2428.8387096774195
09:42:18.410 INFO  b.hashmade.spark.DatastaxSparkTest - Salt Lake City : 989.0
09:42:18.413 INFO  b.hashmade.spark.DatastaxSparkTest - Newark : 1904.1311475409836
09:42:18.419 INFO  b.hashmade.spark.DatastaxSparkTest - El Paso : 551.0
09:42:18.422 INFO  b.hashmade.spark.DatastaxSparkTest - Ontario : 1188.0
09:42:18.425 INFO  b.hashmade.spark.DatastaxSparkTest - Hartford : 1471.0
09:42:18.429 INFO  b.hashmade.spark.DatastaxSparkTest - San Antonio : 247.0
09:42:18.432 INFO  b.hashmade.spark.DatastaxSparkTest - Omaha : 583.0
09:42:18.435 INFO  b.hashmade.spark.DatastaxSparkTest - Portland : 1616.0
09:42:18.438 INFO  b.hashmade.spark.DatastaxSparkTest - Las Vegas : 1605.6666666666667
09:42:18.444 INFO  b.hashmade.spark.DatastaxSparkTest - Austin : 520.7835051546392
09:42:18.450 INFO  b.hashmade.spark.DatastaxSparkTest - Charlotte : 936.0
09:42:18.453 INFO  b.hashmade.spark.DatastaxSparkTest - Houston : 619.5172413793103
09:42:18.460 INFO  b.hashmade.spark.DatastaxSparkTest - Kansas City : 441.0
09:42:18.462 INFO  b.hashmade.spark.DatastaxSparkTest - Chicago : 906.5361010830325
09:42:18.467 INFO  b.hashmade.spark.DatastaxSparkTest - Palm Springs : 1126.0
09:42:18.470 INFO  b.hashmade.spark.DatastaxSparkTest - Honolulu : 3112.8231707317073
09:42:18.475 INFO  b.hashmade.spark.DatastaxSparkTest - Fort Lauderdale : 1182.0
09:42:18.481 INFO  b.hashmade.spark.DatastaxSparkTest - San Juan : 1045.0
09:42:18.484 INFO  b.hashmade.spark.DatastaxSparkTest - Louisville : 733.0
09:42:18.487 INFO  b.hashmade.spark.DatastaxSparkTest - San Francisco : 2099.5552486187844
09:42:18.493 INFO  b.hashmade.spark.DatastaxSparkTest - San Diego : 1558.4528301886792
09:42:18.498 INFO  b.hashmade.spark.DatastaxSparkTest - Mission/McAllen/Edinburg : 469.0
09:42:18.503 INFO  b.hashmade.spark.DatastaxSparkTest - West Palm Beach/Palm Beach : 1123.0
09:42:18.507 INFO  b.hashmade.spark.DatastaxSparkTest - Fayetteville : 280.0
09:42:18.510 INFO  b.hashmade.spark.DatastaxSparkTest - Wichita : 328.0
09:42:18.513 INFO  b.hashmade.spark.DatastaxSparkTest - Memphis : 432.0
09:42:18.516 INFO  b.hashmade.spark.DatastaxSparkTest - Kahului : 2881.043010752688
09:42:18.521 INFO  b.hashmade.spark.DatastaxSparkTest - St. Louis : 752.1764705882352
09:42:18.525 INFO  b.hashmade.spark.DatastaxSparkTest - Orlando : 1313.7662337662337
09:42:18.530 INFO  b.hashmade.spark.DatastaxSparkTest - Oklahoma City : 175.0
09:42:18.533 INFO  b.hashmade.spark.DatastaxSparkTest - Phoenix : 1154.0
09:42:18.535 INFO  b.hashmade.spark.DatastaxSparkTest - Santa Ana : 1315.5151515151515
09:42:18.541 INFO  b.hashmade.spark.DatastaxSparkTest - Baltimore : 1217.0
09:42:18.544 INFO  b.hashmade.spark.DatastaxSparkTest - Burbank : 1231.0
09:42:18.546 INFO  b.hashmade.spark.DatastaxSparkTest - Miami : 1404.1875808538164
09:42:18.551 INFO  b.hashmade.spark.DatastaxSparkTest - Kona : 2504.0
09:42:18.554 INFO  b.hashmade.spark.DatastaxSparkTest - New York : 1639.402862985685
09:42:18.559 INFO  b.hashmade.spark.DatastaxSparkTest - Norfolk : 1212.0
09:42:18.562 INFO  b.hashmade.spark.DatastaxSparkTest - San Jose : 1643.7894736842106
09:42:18.567 INFO  b.hashmade.spark.DatastaxSparkTest - Philadelphia : 1303.0
09:42:18.570 INFO  b.hashmade.spark.DatastaxSparkTest - Minneapolis : 852.0
09:42:18.573 INFO  b.hashmade.spark.DatastaxSparkTest - Lihue : 2615.0
09:42:18.575 INFO  b.hashmade.spark.DatastaxSparkTest - Tampa : 789.25
09:42:18.578 INFO  b.hashmade.spark.DatastaxSparkTest - Fort Myers : 1120.0
09:42:18.581 INFO  b.hashmade.spark.DatastaxSparkTest - Dayton : 861.0
09:42:18.584 INFO  b.hashmade.spark.DatastaxSparkTest - Colorado Springs : 592.0
09:42:18.589 INFO  b.hashmade.spark.DatastaxSparkTest - Boston : 1871.1462264150944
09:42:18.594 INFO  b.hashmade.spark.DatastaxSparkTest - Tulsa : 448.61290322580646
09:42:18.599 INFO  b.hashmade.spark.DatastaxSparkTest - Los Angeles : 2424.0010449320794
09:42:18.605 INFO  b.hashmade.spark.DatastaxSparkTest - Atlanta : 731.0
09:42:18.608 INFO  b.hashmade.spark.DatastaxSparkTest - Indianapolis : 761.0
09:42:18.611 INFO  b.hashmade.spark.DatastaxSparkTest - Charlotte Amalie : 1623.0
09:42:18.616 INFO  b.hashmade.spark.DatastaxSparkTest - Dallas/Fort Worth : 1040.072087912088
09:45:00.250 INFO  o.a.cassandra.thrift.ThriftServer - Stop listening to thrift clients
09:45:00.280 INFO  o.apache.cassandra.transport.Server - Stop listening for CQL clients
09:45:00.285 INFO  org.apache.cassandra.gms.Gossiper - Announcing shutdown
09:45:02.287 INFO  o.a.cassandra.net.MessagingService - Waiting for messaging service to quiesce
09:45:31.300 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:45:31.418 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:45:31.706 INFO  o.a.c.config.DatabaseDescriptor - DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
09:45:31.730 INFO  o.a.c.config.DatabaseDescriptor - Global memtable on-heap threshold is enabled at 450MB
09:45:31.735 INFO  o.a.c.config.DatabaseDescriptor - Global memtable off-heap threshold is enabled at 450MB
09:45:31.943 WARN  o.a.c.config.DatabaseDescriptor - Please rename encryption_options as server_encryption_options in the yaml
09:45:32.180 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:45:32.195 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:45:32.270 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:45:32.287 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:45:33.799 INFO  o.a.c.config.DatabaseDescriptor - Couldn't detect any schema definitions in local storage.
09:45:33.806 INFO  o.a.c.config.DatabaseDescriptor - To create keyspaces and column families, see 'help create' in cqlsh.
09:45:34.125 INFO  o.a.c.io.sstable.IndexSummaryManager - Initializing index summary manager with a memory pool size of 13 MB and a resize interval of 60 minutes
09:45:34.154 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:45:34.164 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:45:34.284 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:45:34.295 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:45:34.389 INFO  o.a.cassandra.net.MessagingService - Starting Messaging Service on port 7010
09:45:34.411 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:45:34.424 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:45:34.513 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:45:34.524 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:45:34.603 INFO  o.a.c.config.YamlConfigurationLoader - Loading settings from file:C:/Users/mdoctor/monalGitRepo/sparkJavaTest/target/embeddedCassandra/cu-cassandra.yaml
09:45:34.614 INFO  o.a.c.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
09:45:35.337 INFO  o.apache.cassandra.transport.Server - Using Netty Version: [netty-buffer=netty-buffer-4.0.23.Final.208198c, netty-codec=netty-codec-4.0.23.Final.208198c, netty-codec-http=netty-codec-http-4.0.23.Final.208198c, netty-codec-socks=netty-codec-socks-4.0.23.Final.208198c, netty-common=netty-common-4.0.23.Final.208198c, netty-handler=netty-handler-4.0.23.Final.208198c, netty-transport=netty-transport-4.0.23.Final.208198c, netty-transport-rxtx=netty-transport-rxtx-4.0.23.Final.208198c, netty-transport-sctp=netty-transport-sctp-4.0.23.Final.208198c, netty-transport-udt=netty-transport-udt-4.0.23.Final.208198c]
09:45:35.361 INFO  o.apache.cassandra.transport.Server - Starting listening for CQL clients on localhost/127.0.0.1:9142...
09:45:35.591 INFO  o.a.cassandra.thrift.ThriftServer - Binding thrift service to localhost/127.0.0.1:9171
09:45:35.604 INFO  o.a.cassandra.thrift.ThriftServer - Listening for thrift clients...
09:45:48.594 ERROR b.hashmade.spark.util.RoadTripUtil - Keyspace roadtrips already exists
com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.exceptions.AlreadyExistsException.copy(AlreadyExistsException.java:85) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.extractCauseFromExecutionException(DefaultResultSetFuture.java:259) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:175) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:52) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:36) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.cassandraunit.CQLDataLoader.load(CQLDataLoader.java:36) ~[cassandra-unit-2.0.2.2.jar:na]
	at blog.hashmade.spark.util.RoadTripUtil.initCassandraWithRoadTrips(RoadTripUtil.java:46) ~[classes/:na]
	at blog.hashmade.spark.DatastaxSparkTest.main(DatastaxSparkTest.java:30) [classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_25]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_25]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_25]
	at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_25]
	at org.codehaus.mojo.exec.ExecJavaMojo$1.run(ExecJavaMojo.java:297) [exec-maven-plugin-1.2.1.jar:na]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_25]
Caused by: com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.exceptions.AlreadyExistsException.copy(AlreadyExistsException.java:85) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:105) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.DefaultResultSetFuture.onSet(DefaultResultSetFuture.java:110) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.RequestHandler.setFinalResult(RequestHandler.java:246) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.RequestHandler.onSet(RequestHandler.java:418) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Connection$Dispatcher.messageReceived(Connection.java:661) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:318) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) ~[netty-3.9.0.Final.jar:na]
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) ~[netty-3.9.0.Final.jar:na]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_25]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_25]
	... 1 common frames omitted
Caused by: com.datastax.driver.core.exceptions.AlreadyExistsException: Keyspace roadtrips already exists
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:70) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:38) ~[cassandra-driver-core-2.1.2.jar:na]
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:168) ~[cassandra-driver-core-2.1.2.jar:na]
	at org.jboss.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:66) ~[netty-3.9.0.Final.jar:na]
	... 21 common frames omitted
09:45:49.079 INFO  org.apache.spark.SecurityManager - Changing view acls to: mdoctor,
09:45:49.084 INFO  org.apache.spark.SecurityManager - Changing modify acls to: mdoctor,
09:45:49.089 INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(mdoctor, ); users with modify permissions: Set(mdoctor, )
09:45:49.531 INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
09:45:49.599 INFO  Remoting - Starting remoting
09:45:49.731 INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54864]
09:45:49.744 INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54864.
09:45:49.745 INFO  Remoting - Remoting now listens on addresses: [akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54864]
09:45:49.770 INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
09:45:49.780 INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
09:45:49.797 INFO  o.a.spark.storage.DiskBlockManager - Created local directory at C:\Users\mdoctor\AppData\Local\Temp\spark-local-20150105094549-f083
09:45:49.818 INFO  org.apache.spark.util.Utils - Successfully started service 'Connection manager for block manager' on port 54867.
09:45:49.825 INFO  o.a.spark.network.ConnectionManager - Bound socket to port 54867 with id = ConnectionManagerId(MDOCTOR.chi.chicorp,54867)
09:45:49.833 INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 972.5 MB
09:45:49.837 INFO  o.a.spark.storage.BlockManagerMaster - Trying to register BlockManager
09:45:49.838 INFO  o.a.s.s.BlockManagerMasterActor - Registering block manager MDOCTOR.chi.chicorp:54867 with 972.5 MB RAM
09:45:49.841 INFO  o.a.spark.storage.BlockManagerMaster - Registered BlockManager
09:45:49.859 INFO  org.apache.spark.HttpFileServer - HTTP File server directory is C:\Users\mdoctor\AppData\Local\Temp\spark-7ae9b64f-2608-4d19-bfe5-14973f0d7541
09:45:49.875 INFO  org.apache.spark.HttpServer - Starting HTTP Server
09:45:49.947 INFO  org.eclipse.jetty.server.Server - jetty-8.1.14.v20131031
09:45:49.972 INFO  o.e.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:54868
09:45:49.977 INFO  org.apache.spark.util.Utils - Successfully started service 'HTTP file server' on port 54868.
09:45:50.465 INFO  org.eclipse.jetty.server.Server - jetty-8.1.14.v20131031
09:45:50.476 INFO  o.e.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
09:45:50.480 INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
09:45:50.488 INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://MDOCTOR.chi.chicorp:4040
09:45:50.694 INFO  org.apache.spark.util.AkkaUtils - Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@MDOCTOR.chi.chicorp:54864/user/HeartbeatReceiver
09:45:51.052 INFO  c.d.s.c.cql.CassandraConnector - Connected to Cassandra cluster: CassClusterDev001
09:45:51.059 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:45:51.063 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:45:51.063 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:45:51.070 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:45:51.075 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:45:51.104 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:45:51.108 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:45:51.115 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:45:51.117 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:45:51.120 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:45:51.523 INFO  c.d.s.c.cql.CassandraConnector - Disconnected from Cassandra cluster: CassClusterDev001
09:45:51.662 INFO  org.apache.spark.SparkContext - Starting job: collect at DatastaxSparkTest.java:80
09:45:51.678 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 1 (groupBy at DatastaxSparkTest.java:66)
09:45:51.681 INFO  o.a.spark.scheduler.DAGScheduler - Got job 0 (collect at DatastaxSparkTest.java:80) with 2 output partitions (allowLocal=false)
09:45:51.681 INFO  o.a.spark.scheduler.DAGScheduler - Final stage: Stage 0(collect at DatastaxSparkTest.java:80)
09:45:51.681 INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 1)
09:45:51.686 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(Stage 1)
09:45:51.691 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 1 (MappedRDD[1] at groupBy at DatastaxSparkTest.java:66), which has no missing parents
09:45:51.748 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(6456) called with curMem=0, maxMem=1019782103
09:45:51.749 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 6.3 KB, free 972.5 MB)
09:45:51.773 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 1 (MappedRDD[1] at groupBy at DatastaxSparkTest.java:66)
09:45:51.774 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 2 tasks
09:45:51.798 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 0, localhost, ANY, 25221 bytes)
09:45:51.804 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 0)
09:45:51.837 INFO  org.apache.spark.CacheManager - Partition rdd_0_0 not found, computing it
09:45:52.022 INFO  c.d.s.c.cql.CassandraConnector - Connected to Cassandra cluster: CassClusterDev001
09:45:52.022 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:45:52.022 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:45:52.026 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:45:52.031 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:45:52.036 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:45:52.067 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:45:52.068 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:45:52.073 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.98 (datacenter1)
09:45:52.079 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:45:52.085 INFO  c.d.s.c.c.LocalNodeFirstLoadBalancingPolicy - Adding host 172.28.65.97 (datacenter1)
09:45:54.476 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2372497) called with curMem=6456, maxMem=1019782103
09:45:54.476 INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_0 stored as values in memory (estimated size 2.3 MB, free 970.3 MB)
09:45:54.477 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_0 in memory on MDOCTOR.chi.chicorp:54867 (size: 2.3 MB, free: 970.3 MB)
09:45:54.478 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_0_0
09:45:54.681 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 0). 1385 bytes result sent to driver
09:45:54.683 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 1, localhost, ANY, 25283 bytes)
09:45:54.684 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 1)
09:45:54.691 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 0) in 2896 ms on localhost (1/2)
09:45:54.694 INFO  org.apache.spark.CacheManager - Partition rdd_0_1 not found, computing it
09:45:56.264 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2549804) called with curMem=2378953, maxMem=1019782103
09:45:56.264 INFO  org.apache.spark.storage.MemoryStore - Block rdd_0_1 stored as values in memory (estimated size 2.4 MB, free 967.8 MB)
09:45:56.264 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_0_1 in memory on MDOCTOR.chi.chicorp:54867 (size: 2.4 MB, free: 967.8 MB)
09:45:56.265 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_0_1
09:45:56.324 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 1). 1385 bytes result sent to driver
09:45:56.327 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 1) in 1646 ms on localhost (2/2)
09:45:56.328 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
09:45:56.328 INFO  o.a.spark.scheduler.DAGScheduler - Stage 1 (groupBy at DatastaxSparkTest.java:66) finished in 4.547 s
09:45:56.329 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:45:56.329 INFO  o.a.spark.scheduler.DAGScheduler - running: Set()
09:45:56.329 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 0)
09:45:56.330 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:45:56.332 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 0: List()
09:45:56.335 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 0 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72), which is now runnable
09:45:56.336 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2864) called with curMem=4928757, maxMem=1019782103
09:45:56.336 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 2.8 KB, free 967.8 MB)
09:45:56.342 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 0 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72)
09:45:56.342 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 2 tasks
09:45:56.343 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 2, localhost, PROCESS_LOCAL, 948 bytes)
09:45:56.343 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 2)
09:45:56.345 INFO  org.apache.spark.CacheManager - Partition rdd_4_0 not found, computing it
09:45:56.351 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:45:56.353 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 2 non-empty blocks out of 2 blocks
09:45:56.354 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 4 ms
09:45:56.602 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3080) called with curMem=4931621, maxMem=1019782103
09:45:56.602 INFO  org.apache.spark.storage.MemoryStore - Block rdd_4_0 stored as values in memory (estimated size 3.0 KB, free 967.8 MB)
09:45:56.603 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_4_0 in memory on MDOCTOR.chi.chicorp:54867 (size: 3.0 KB, free: 967.8 MB)
09:45:56.603 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_4_0
09:45:56.604 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 2). 2313 bytes result sent to driver
09:45:56.605 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 3, localhost, PROCESS_LOCAL, 948 bytes)
09:45:56.606 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 3)
09:45:56.607 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 2) in 263 ms on localhost (1/2)
09:45:56.607 INFO  org.apache.spark.CacheManager - Partition rdd_4_1 not found, computing it
09:45:56.608 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:45:56.608 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 2 non-empty blocks out of 2 blocks
09:45:56.608 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:45:56.758 INFO  c.d.s.c.cql.CassandraConnector - Disconnected from Cassandra cluster: CassClusterDev001
09:45:56.811 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3064) called with curMem=4934701, maxMem=1019782103
09:45:56.811 INFO  org.apache.spark.storage.MemoryStore - Block rdd_4_1 stored as values in memory (estimated size 3.0 KB, free 967.8 MB)
09:45:56.811 INFO  o.a.spark.storage.BlockManagerInfo - Added rdd_4_1 in memory on MDOCTOR.chi.chicorp:54867 (size: 3.0 KB, free: 967.8 MB)
09:45:56.812 INFO  o.a.spark.storage.BlockManagerMaster - Updated info of block rdd_4_1
09:45:56.812 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 3). 2279 bytes result sent to driver
09:45:56.814 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 3) in 209 ms on localhost (2/2)
09:45:56.814 INFO  o.a.spark.scheduler.DAGScheduler - Stage 0 (collect at DatastaxSparkTest.java:80) finished in 0.472 s
09:45:56.814 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
09:45:56.821 INFO  org.apache.spark.SparkContext - Job finished: collect at DatastaxSparkTest.java:80, took 5.158852812 s
09:45:56.824 INFO  b.hashmade.spark.DatastaxSparkTest - Nb RoadTrips by origin
09:45:56.826 INFO  b.hashmade.spark.DatastaxSparkTest - Albuquerque : 61
09:45:56.829 INFO  b.hashmade.spark.DatastaxSparkTest - Raleigh/Durham : 62
09:45:56.835 INFO  b.hashmade.spark.DatastaxSparkTest - Columbus : 31
09:45:56.837 INFO  b.hashmade.spark.DatastaxSparkTest - Washington : 358
09:45:56.841 INFO  b.hashmade.spark.DatastaxSparkTest - Seattle : 31
09:45:56.845 INFO  b.hashmade.spark.DatastaxSparkTest - Salt Lake City : 31
09:45:56.848 INFO  b.hashmade.spark.DatastaxSparkTest - Newark : 61
09:45:56.851 INFO  b.hashmade.spark.DatastaxSparkTest - El Paso : 31
09:45:56.853 INFO  b.hashmade.spark.DatastaxSparkTest - Ontario : 36
09:45:56.856 INFO  b.hashmade.spark.DatastaxSparkTest - Hartford : 31
09:45:56.859 INFO  b.hashmade.spark.DatastaxSparkTest - San Antonio : 176
09:45:56.862 INFO  b.hashmade.spark.DatastaxSparkTest - Omaha : 57
09:45:56.865 INFO  b.hashmade.spark.DatastaxSparkTest - Las Vegas : 93
09:45:56.868 INFO  b.hashmade.spark.DatastaxSparkTest - Portland : 9
09:45:56.870 INFO  b.hashmade.spark.DatastaxSparkTest - Austin : 194
09:45:56.874 INFO  b.hashmade.spark.DatastaxSparkTest - Charlotte : 31
09:45:56.877 INFO  b.hashmade.spark.DatastaxSparkTest - Houston : 58
09:45:56.880 INFO  b.hashmade.spark.DatastaxSparkTest - Kansas City : 93
09:45:56.884 INFO  b.hashmade.spark.DatastaxSparkTest - Chicago : 1108
09:45:56.887 INFO  b.hashmade.spark.DatastaxSparkTest - Palm Springs : 31
09:45:56.891 INFO  b.hashmade.spark.DatastaxSparkTest - Honolulu : 164
09:45:56.894 INFO  b.hashmade.spark.DatastaxSparkTest - San Juan : 62
09:45:56.897 INFO  b.hashmade.spark.DatastaxSparkTest - Fort Lauderdale : 31
09:45:56.906 INFO  b.hashmade.spark.DatastaxSparkTest - Louisville : 1
09:45:56.910 INFO  b.hashmade.spark.DatastaxSparkTest - San Francisco : 362
09:45:56.912 INFO  b.hashmade.spark.DatastaxSparkTest - San Diego : 159
09:45:56.916 INFO  b.hashmade.spark.DatastaxSparkTest - Mission/McAllen/Edinburg : 30
09:45:56.921 INFO  b.hashmade.spark.DatastaxSparkTest - West Palm Beach/Palm Beach : 62
09:45:56.926 INFO  b.hashmade.spark.DatastaxSparkTest - Fayetteville : 31
09:45:56.929 INFO  b.hashmade.spark.DatastaxSparkTest - Wichita : 62
09:45:56.933 INFO  b.hashmade.spark.DatastaxSparkTest - Memphis : 24
09:45:56.936 INFO  b.hashmade.spark.DatastaxSparkTest - Kahului : 93
09:45:56.939 INFO  b.hashmade.spark.DatastaxSparkTest - St. Louis : 204
09:45:56.942 INFO  b.hashmade.spark.DatastaxSparkTest - Orlando : 154
09:45:56.945 INFO  b.hashmade.spark.DatastaxSparkTest - Oklahoma City : 31
09:45:56.948 INFO  b.hashmade.spark.DatastaxSparkTest - Phoenix : 124
09:45:56.950 INFO  b.hashmade.spark.DatastaxSparkTest - Santa Ana : 33
09:45:56.954 INFO  b.hashmade.spark.DatastaxSparkTest - Baltimore : 27
09:45:56.961 INFO  b.hashmade.spark.DatastaxSparkTest - Burbank : 8
09:45:56.964 INFO  b.hashmade.spark.DatastaxSparkTest - Miami : 773
09:45:56.967 INFO  b.hashmade.spark.DatastaxSparkTest - Kona : 31
09:45:56.970 INFO  b.hashmade.spark.DatastaxSparkTest - New York : 978
09:45:56.973 INFO  b.hashmade.spark.DatastaxSparkTest - Norfolk : 50
09:45:56.979 INFO  b.hashmade.spark.DatastaxSparkTest - San Jose : 57
09:45:56.981 INFO  b.hashmade.spark.DatastaxSparkTest - Philadelphia : 8
09:45:56.985 INFO  b.hashmade.spark.DatastaxSparkTest - Minneapolis : 30
09:45:56.988 INFO  b.hashmade.spark.DatastaxSparkTest - Lihue : 42
09:45:56.990 INFO  b.hashmade.spark.DatastaxSparkTest - Tampa : 124
09:45:56.993 INFO  b.hashmade.spark.DatastaxSparkTest - Fort Myers : 31
09:45:56.997 INFO  b.hashmade.spark.DatastaxSparkTest - Dayton : 31
09:45:57.000 INFO  b.hashmade.spark.DatastaxSparkTest - Colorado Springs : 31
09:45:57.002 INFO  b.hashmade.spark.DatastaxSparkTest - Boston : 212
09:45:57.005 INFO  b.hashmade.spark.DatastaxSparkTest - Tulsa : 62
09:45:57.008 INFO  b.hashmade.spark.DatastaxSparkTest - Los Angeles : 957
09:45:57.011 INFO  b.hashmade.spark.DatastaxSparkTest - Atlanta : 31
09:45:57.013 INFO  b.hashmade.spark.DatastaxSparkTest - Indianapolis : 1
09:45:57.016 INFO  b.hashmade.spark.DatastaxSparkTest - Dallas/Fort Worth : 2275
09:45:57.021 INFO  b.hashmade.spark.DatastaxSparkTest - Charlotte Amalie : 31
09:45:57.057 INFO  org.apache.spark.SparkContext - Starting job: collect at DatastaxSparkTest.java:103
09:45:57.059 INFO  o.a.spark.MapOutputTrackerMaster - Size of output statuses for shuffle 0 is 153 bytes
09:45:57.061 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 4 (mapToPair at DatastaxSparkTest.java:72)
09:45:57.061 INFO  o.a.spark.scheduler.DAGScheduler - Registering RDD 5 (mapToPair at DatastaxSparkTest.java:86)
09:45:57.061 INFO  o.a.spark.scheduler.DAGScheduler - Got job 1 (collect at DatastaxSparkTest.java:103) with 2 output partitions (allowLocal=false)
09:45:57.061 INFO  o.a.spark.scheduler.DAGScheduler - Final stage: Stage 2(collect at DatastaxSparkTest.java:103)
09:45:57.062 INFO  o.a.spark.scheduler.DAGScheduler - Parents of final stage: List(Stage 5, Stage 4)
09:45:57.063 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents: List(Stage 5, Stage 4)
09:45:57.063 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 4 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72), which has no missing parents
09:45:57.064 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(2768) called with curMem=4937765, maxMem=1019782103
09:45:57.064 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 2.7 KB, free 967.8 MB)
09:45:57.065 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 4 (MappedRDD[4] at mapToPair at DatastaxSparkTest.java:72)
09:45:57.065 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 2 tasks
09:45:57.066 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4, localhost, ANY, 937 bytes)
09:45:57.066 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
09:45:57.067 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 5 (MappedRDD[5] at mapToPair at DatastaxSparkTest.java:86), which has no missing parents
09:45:57.069 INFO  o.apache.spark.storage.BlockManager - Found block rdd_4_0 locally
09:45:57.075 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(6464) called with curMem=4940533, maxMem=1019782103
09:45:57.075 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 6.3 KB, free 967.8 MB)
09:45:57.078 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 5 (MappedRDD[5] at mapToPair at DatastaxSparkTest.java:86)
09:45:57.078 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 2 tasks
09:45:57.089 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1874 bytes result sent to driver
09:45:57.089 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 4.0 (TID 5, localhost, ANY, 937 bytes)
09:45:57.090 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 4.0 (TID 5)
09:45:57.090 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 24 ms on localhost (1/2)
09:45:57.093 INFO  o.apache.spark.storage.BlockManager - Found block rdd_4_1 locally
09:45:57.095 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 4.0 (TID 5). 1874 bytes result sent to driver
09:45:57.096 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 6, localhost, ANY, 25221 bytes)
09:45:57.097 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 4.0 (TID 5) in 7 ms on localhost (2/2)
09:45:57.097 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
09:45:57.097 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 6)
09:45:57.097 INFO  o.a.spark.scheduler.DAGScheduler - Stage 4 (mapToPair at DatastaxSparkTest.java:72) finished in 0.031 s
09:45:57.097 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:45:57.097 INFO  o.a.spark.scheduler.DAGScheduler - running: Set(Stage 5)
09:45:57.097 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 2)
09:45:57.097 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:45:57.100 INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_0 locally
09:45:57.103 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List(Stage 5)
09:45:57.124 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 6). 1874 bytes result sent to driver
09:45:57.126 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 7, localhost, ANY, 25283 bytes)
09:45:57.127 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 7)
09:45:57.127 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 6) in 32 ms on localhost (1/2)
09:45:57.135 INFO  o.apache.spark.storage.BlockManager - Found block rdd_0_1 locally
09:45:57.153 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 7). 1874 bytes result sent to driver
09:45:57.154 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 7) in 30 ms on localhost (2/2)
09:45:57.154 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
09:45:57.155 INFO  o.a.spark.scheduler.DAGScheduler - Stage 5 (mapToPair at DatastaxSparkTest.java:86) finished in 0.077 s
09:45:57.155 INFO  o.a.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:45:57.155 INFO  o.a.spark.scheduler.DAGScheduler - running: Set()
09:45:57.155 INFO  o.a.spark.scheduler.DAGScheduler - waiting: Set(Stage 2)
09:45:57.155 INFO  o.a.spark.scheduler.DAGScheduler - failed: Set()
09:45:57.157 INFO  o.a.spark.scheduler.DAGScheduler - Missing parents for Stage 2: List()
09:45:57.157 INFO  o.a.spark.scheduler.DAGScheduler - Submitting Stage 2 (MappedValuesRDD[10] at mapValues at DatastaxSparkTest.java:98), which is now runnable
09:45:57.158 INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(3384) called with curMem=4946997, maxMem=1019782103
09:45:57.158 INFO  org.apache.spark.storage.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 3.3 KB, free 967.8 MB)
09:45:57.162 INFO  o.a.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 2 (MappedValuesRDD[10] at mapValues at DatastaxSparkTest.java:98)
09:45:57.162 INFO  o.a.s.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 2 tasks
09:45:57.163 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 8, localhost, PROCESS_LOCAL, 3237 bytes)
09:45:57.163 INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 8)
09:45:57.166 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:45:57.166 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 2 non-empty blocks out of 2 blocks
09:45:57.166 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:45:57.170 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:45:57.170 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 1 non-empty blocks out of 2 blocks
09:45:57.170 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:45:57.181 INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 8). 1921 bytes result sent to driver
09:45:57.181 INFO  o.a.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 9, localhost, PROCESS_LOCAL, 3237 bytes)
09:45:57.182 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 8) in 18 ms on localhost (1/2)
09:45:57.182 INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 9)
09:45:57.183 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:45:57.183 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 2 non-empty blocks out of 2 blocks
09:45:57.183 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:45:57.185 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
09:45:57.186 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 1 non-empty blocks out of 2 blocks
09:45:57.186 INFO  o.a.s.s.BlockFetcherIterator$BasicBlockFetcherIterator - Started 0 remote fetches in 1 ms
09:45:57.188 INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 9). 1872 bytes result sent to driver
09:45:57.189 INFO  o.a.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 9) in 8 ms on localhost (2/2)
09:45:57.189 INFO  o.a.spark.scheduler.DAGScheduler - Stage 2 (collect at DatastaxSparkTest.java:103) finished in 0.027 s
09:45:57.189 INFO  o.a.s.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
09:45:57.190 INFO  org.apache.spark.SparkContext - Job finished: collect at DatastaxSparkTest.java:103, took 0.133184856 s
09:45:57.190 INFO  b.hashmade.spark.DatastaxSparkTest - Average distance by origin
09:45:57.194 INFO  b.hashmade.spark.DatastaxSparkTest - Albuquerque : 569.0
09:45:57.197 INFO  b.hashmade.spark.DatastaxSparkTest - Raleigh/Durham : 880.5
09:45:57.201 INFO  b.hashmade.spark.DatastaxSparkTest - Columbus : 926.0
09:45:57.204 INFO  b.hashmade.spark.DatastaxSparkTest - Washington : 1322.2067039106146
09:45:57.209 INFO  b.hashmade.spark.DatastaxSparkTest - Seattle : 2428.8387096774195
09:45:57.214 INFO  b.hashmade.spark.DatastaxSparkTest - Salt Lake City : 989.0
09:45:57.218 INFO  b.hashmade.spark.DatastaxSparkTest - Newark : 1904.1311475409836
09:45:57.224 INFO  b.hashmade.spark.DatastaxSparkTest - El Paso : 551.0
09:45:57.227 INFO  b.hashmade.spark.DatastaxSparkTest - Ontario : 1188.0
09:45:57.230 INFO  b.hashmade.spark.DatastaxSparkTest - Hartford : 1471.0
09:45:57.233 INFO  b.hashmade.spark.DatastaxSparkTest - San Antonio : 247.0
09:45:57.236 INFO  b.hashmade.spark.DatastaxSparkTest - Omaha : 583.0
09:45:57.239 INFO  b.hashmade.spark.DatastaxSparkTest - Portland : 1616.0
09:45:57.241 INFO  b.hashmade.spark.DatastaxSparkTest - Las Vegas : 1605.6666666666667
09:45:57.246 INFO  b.hashmade.spark.DatastaxSparkTest - Austin : 520.7835051546392
09:45:57.251 INFO  b.hashmade.spark.DatastaxSparkTest - Charlotte : 936.0
09:45:57.254 INFO  b.hashmade.spark.DatastaxSparkTest - Houston : 619.5172413793103
09:45:57.259 INFO  b.hashmade.spark.DatastaxSparkTest - Kansas City : 441.0
09:45:57.262 INFO  b.hashmade.spark.DatastaxSparkTest - Chicago : 906.5361010830325
09:45:57.267 INFO  b.hashmade.spark.DatastaxSparkTest - Palm Springs : 1126.0
09:45:57.270 INFO  b.hashmade.spark.DatastaxSparkTest - Honolulu : 3112.8231707317073
09:45:57.274 INFO  b.hashmade.spark.DatastaxSparkTest - Fort Lauderdale : 1182.0
09:45:57.280 INFO  b.hashmade.spark.DatastaxSparkTest - San Juan : 1045.0
09:45:57.283 INFO  b.hashmade.spark.DatastaxSparkTest - Louisville : 733.0
09:45:57.286 INFO  b.hashmade.spark.DatastaxSparkTest - San Francisco : 2099.5552486187844
09:45:57.290 INFO  b.hashmade.spark.DatastaxSparkTest - San Diego : 1558.4528301886792
09:45:57.296 INFO  b.hashmade.spark.DatastaxSparkTest - Mission/McAllen/Edinburg : 469.0
09:45:57.301 INFO  b.hashmade.spark.DatastaxSparkTest - West Palm Beach/Palm Beach : 1123.0
09:45:57.306 INFO  b.hashmade.spark.DatastaxSparkTest - Fayetteville : 280.0
09:45:57.309 INFO  b.hashmade.spark.DatastaxSparkTest - Wichita : 328.0
09:45:57.312 INFO  b.hashmade.spark.DatastaxSparkTest - Memphis : 432.0
09:45:57.314 INFO  b.hashmade.spark.DatastaxSparkTest - Kahului : 2881.043010752688
09:45:57.319 INFO  b.hashmade.spark.DatastaxSparkTest - St. Louis : 752.1764705882352
09:45:57.324 INFO  b.hashmade.spark.DatastaxSparkTest - Orlando : 1313.7662337662337
09:45:57.330 INFO  b.hashmade.spark.DatastaxSparkTest - Oklahoma City : 175.0
09:45:57.333 INFO  b.hashmade.spark.DatastaxSparkTest - Phoenix : 1154.0
09:45:57.336 INFO  b.hashmade.spark.DatastaxSparkTest - Santa Ana : 1315.5151515151515
09:45:57.340 INFO  b.hashmade.spark.DatastaxSparkTest - Baltimore : 1217.0
09:45:57.343 INFO  b.hashmade.spark.DatastaxSparkTest - Burbank : 1231.0
09:45:57.346 INFO  b.hashmade.spark.DatastaxSparkTest - Miami : 1404.1875808538164
09:45:57.351 INFO  b.hashmade.spark.DatastaxSparkTest - Kona : 2504.0
09:45:57.354 INFO  b.hashmade.spark.DatastaxSparkTest - New York : 1639.402862985685
09:45:57.359 INFO  b.hashmade.spark.DatastaxSparkTest - Norfolk : 1212.0
09:45:57.362 INFO  b.hashmade.spark.DatastaxSparkTest - San Jose : 1643.7894736842106
09:45:57.367 INFO  b.hashmade.spark.DatastaxSparkTest - Philadelphia : 1303.0
09:45:57.370 INFO  b.hashmade.spark.DatastaxSparkTest - Minneapolis : 852.0
09:45:57.373 INFO  b.hashmade.spark.DatastaxSparkTest - Lihue : 2615.0
09:45:57.377 INFO  b.hashmade.spark.DatastaxSparkTest - Tampa : 789.25
09:45:57.380 INFO  b.hashmade.spark.DatastaxSparkTest - Fort Myers : 1120.0
09:45:57.383 INFO  b.hashmade.spark.DatastaxSparkTest - Dayton : 861.0
09:45:57.386 INFO  b.hashmade.spark.DatastaxSparkTest - Colorado Springs : 592.0
09:45:57.390 INFO  b.hashmade.spark.DatastaxSparkTest - Boston : 1871.1462264150944
09:45:57.395 INFO  b.hashmade.spark.DatastaxSparkTest - Tulsa : 448.61290322580646
09:45:57.402 INFO  b.hashmade.spark.DatastaxSparkTest - Los Angeles : 2424.0010449320794
09:45:57.407 INFO  b.hashmade.spark.DatastaxSparkTest - Atlanta : 731.0
09:45:57.410 INFO  b.hashmade.spark.DatastaxSparkTest - Indianapolis : 761.0
09:45:57.412 INFO  b.hashmade.spark.DatastaxSparkTest - Charlotte Amalie : 1623.0
09:45:57.417 INFO  b.hashmade.spark.DatastaxSparkTest - Dallas/Fort Worth : 1040.072087912088
